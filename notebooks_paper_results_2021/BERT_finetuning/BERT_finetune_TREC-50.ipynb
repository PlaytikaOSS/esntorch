{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT finetuning on TREC-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "from transformers import BertTokenizer, BertTokenizerFast\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.__version__)\n",
    "# print(torch.cuda.device_count())\n",
    "# print(torch.cuda.is_available())\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 24\n",
    "NB_EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILE = '~/Results/BERT_finetune/trec-50_BERT_finetune_b'+str(BATCH_SIZE)+'_results.pkl'\n",
    "RESULTS_PATH = '~/Results/BERT_finetune/trec-50_b'+str(BATCH_SIZE)+'/'\n",
    "CACHE_DIR = '~/Data/huggignface/'         # path of your  folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset trec (/raid/home/jeremiec/huggingface_datasets/trec/default/1.1.0/751da1ab101b8d297a3d6e9c79ee9b0173ff94c4497b75677b59b61d5467a9b9)\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "\n",
    "raw_datasets = load_dataset('trec', cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc6d3572e4b4c109006e0a0ba976773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a03b5b31c44b3483a8b485ba489111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column('label-fine', 'labels') # 'label-fine'\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "train_val_datasets = train_dataset.train_test_split(train_size=0.8)\n",
    "\n",
    "train_dataset = train_val_datasets['train']\n",
    "val_dataset = train_val_datasets['test']\n",
    "test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of labels\n",
    "\n",
    "num_labels = len(set(train_dataset['labels'].tolist()))\n",
    "# num_labels = 50\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # output\n",
    "    output_dir=RESULTS_PATH,          \n",
    "    \n",
    "    # params\n",
    "    num_train_epochs=NB_EPOCHS,                # nb of epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,    # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,     # cf. paper Sun et al.\n",
    "    learning_rate=2e-5,                        # cf. paper Sun et al.\n",
    "#     warmup_steps=500,                        # number of warmup steps for learning rate scheduler\n",
    "    warmup_ratio=0.1,                          # cf. paper Sun et al.\n",
    "    weight_decay=0.01,                         # strength of weight decay\n",
    "    \n",
    "#     # eval\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "#     evaluation_strategy='no', # no more evaluation, takes time\n",
    "    \n",
    "    # log\n",
    "    logging_dir=RESULTS_PATH+'logs',  \n",
    "    logging_strategy='steps',\n",
    "    logging_steps=10,\n",
    "    \n",
    "    # save\n",
    "#     save_strategy='epoch',\n",
    "    # save_strategy='steps',\n",
    "#     load_best_model_at_end=False\n",
    "    load_best_model_at_end=True               # cf. paper Sun et al.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    \n",
    "    return {\"val_accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    # compute_metrics=compute_metrics,\n",
    "    # callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='728' max='728' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [728/728 10:25, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.839900</td>\n",
       "      <td>3.802250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.795200</td>\n",
       "      <td>3.742054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.704600</td>\n",
       "      <td>3.634381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.609500</td>\n",
       "      <td>3.538632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.475400</td>\n",
       "      <td>3.429383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.402200</td>\n",
       "      <td>3.368422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.284700</td>\n",
       "      <td>3.250541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.282000</td>\n",
       "      <td>3.153093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.027000</td>\n",
       "      <td>3.066735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.097400</td>\n",
       "      <td>2.978224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.907400</td>\n",
       "      <td>2.876144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.868600</td>\n",
       "      <td>2.784625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.658500</td>\n",
       "      <td>2.671196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.666100</td>\n",
       "      <td>2.591214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.463500</td>\n",
       "      <td>2.465001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.413000</td>\n",
       "      <td>2.324645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.357500</td>\n",
       "      <td>2.241085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.184100</td>\n",
       "      <td>2.154693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.151700</td>\n",
       "      <td>2.066127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.983500</td>\n",
       "      <td>1.996028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.961200</td>\n",
       "      <td>1.953913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.841600</td>\n",
       "      <td>1.854786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.856600</td>\n",
       "      <td>1.807634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.743900</td>\n",
       "      <td>1.744916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.676600</td>\n",
       "      <td>1.690261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.708400</td>\n",
       "      <td>1.653914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.595000</td>\n",
       "      <td>1.620005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.535500</td>\n",
       "      <td>1.558159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.567400</td>\n",
       "      <td>1.526989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.453500</td>\n",
       "      <td>1.457645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.296700</td>\n",
       "      <td>1.422124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.336900</td>\n",
       "      <td>1.401843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.407600</td>\n",
       "      <td>1.364024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.355300</td>\n",
       "      <td>1.327365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.357700</td>\n",
       "      <td>1.313211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.354300</td>\n",
       "      <td>1.264024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.358000</td>\n",
       "      <td>1.251905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.078400</td>\n",
       "      <td>1.231586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.020400</td>\n",
       "      <td>1.200117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.041300</td>\n",
       "      <td>1.200531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.077800</td>\n",
       "      <td>1.166460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.984200</td>\n",
       "      <td>1.148153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.125500</td>\n",
       "      <td>1.125797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.062900</td>\n",
       "      <td>1.098705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.920900</td>\n",
       "      <td>1.080908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>1.067129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.988300</td>\n",
       "      <td>1.049350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.006600</td>\n",
       "      <td>1.036624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.967900</td>\n",
       "      <td>1.023622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.030900</td>\n",
       "      <td>1.015889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.037400</td>\n",
       "      <td>1.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.927800</td>\n",
       "      <td>0.982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.830700</td>\n",
       "      <td>0.973444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.915100</td>\n",
       "      <td>0.964705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.778700</td>\n",
       "      <td>0.955952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.866800</td>\n",
       "      <td>0.951420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.892600</td>\n",
       "      <td>0.945091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.935391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.934145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.852900</td>\n",
       "      <td>0.931905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.891600</td>\n",
       "      <td>0.919745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.744100</td>\n",
       "      <td>0.913616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.720500</td>\n",
       "      <td>0.907419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.765300</td>\n",
       "      <td>0.902189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.710500</td>\n",
       "      <td>0.897405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.894506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.702300</td>\n",
       "      <td>0.891607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.666300</td>\n",
       "      <td>0.891688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.723200</td>\n",
       "      <td>0.891369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.673800</td>\n",
       "      <td>0.890244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.738300</td>\n",
       "      <td>0.888131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.727100</td>\n",
       "      <td>0.887509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.58435"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time = results.metrics[\"train_runtime\"]\n",
    "training_time_per_epoch = training_time / training_args.num_train_epochs\n",
    "training_time_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(os.path.join(RESULTS_PATH, 'best_model-0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model-0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.804, 156.58435)\n"
     ]
    }
   ],
   "source": [
    "results_d = {}\n",
    "epoch = 1\n",
    "\n",
    "ordered_files = sorted( [f for f in os.listdir(RESULTS_PATH) \n",
    "                         if (not f.endswith(\"logs\")) and (f.startswith(\"best\")) # best model eval only\n",
    "                        ],\n",
    "                         key=lambda x: int(x.split('-')[1]) )\n",
    "\n",
    "for filename in ordered_files:\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    # load model\n",
    "    model_file = os.path.join(RESULTS_PATH, filename)\n",
    "    finetuned_model = BertForSequenceClassification.from_pretrained(model_file, num_labels=num_labels)\n",
    "    finetuned_model.to(device)\n",
    "    finetuned_model.eval()\n",
    "\n",
    "    # compute test acc\n",
    "    test_trainer = Trainer(finetuned_model, data_collator=DataCollatorWithPadding(tokenizer))\n",
    "\n",
    "    raw_preds, labels, _ = test_trainer.predict(test_dataset)\n",
    "    preds = np.argmax(raw_preds, axis=1)\n",
    "\n",
    "    test_acc = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    \n",
    "#     results_d[filename] = (test_acc, training_time_per_epoch*epoch)\n",
    "    results_d[filename] = test_acc # best model evaluation only\n",
    "    \n",
    "    print((test_acc, training_time_per_epoch*epoch))\n",
    "    \n",
    "    epoch += 1\n",
    "    \n",
    "results_d['training_time'] = training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "\n",
    "with open(RESULTS_FILE, 'wb') as fh:\n",
    "    pickle.dump(results_d, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_model-0': 0.804, 'training_time': 626.3374}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# new and best results with num_labels = 50\n",
    "{'best_model-0': 0.794, 'training_time': 549.1683}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# previous results with num_labels = 47\n",
    "{'best_model-0': 0.776, 'training_time': 1087.6784}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Batch 16\n",
    "\n",
    "{'epoch 1': (0.538, 52.010915),\n",
    " 'epoch 2': (0.616, 104.02183),\n",
    " 'epoch 3': (0.702, 156.03274499999998),\n",
    " 'epoch 4': (0.756, 208.04366),\n",
    " 'epoch 5': (0.784, 260.054575),\n",
    " 'epoch 6': (0.776, 312.06548999999995),\n",
    " 'epoch 7': (0.788, 364.07640499999997),\n",
    " 'epoch 8': (0.804, 416.08732),\n",
    " 'epoch 9': (0.792, 468.098235),\n",
    " 'epoch 10': (0.806, 520.10915),\n",
    " 'epoch 11': (0.774, 572.120065),\n",
    " 'epoch 12': (0.82, 624.1309799999999),\n",
    " 'epoch 13': (0.824, 676.141895),\n",
    " 'epoch 14': (0.814, 728.1528099999999),\n",
    " 'epoch 15': (0.814, 780.163725),\n",
    " 'epoch 16': (0.818, 832.17464),\n",
    " 'epoch 17': (0.816, 884.1855549999999),\n",
    " 'epoch 18': (0.818, 936.19647),\n",
    " 'epoch 19': (0.816, 988.2073849999999),\n",
    " 'epoch 20': (0.814, 1040.2183)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Batch 32\n",
    "\n",
    "{'epoch 1': (0.234, 37.98232),\n",
    " 'epoch 2': (0.538, 75.96464),\n",
    " 'epoch 3': (0.628, 113.94696),\n",
    " 'epoch 4': (0.696, 151.92928),\n",
    " 'epoch 5': (0.748, 189.91160000000002),\n",
    " 'epoch 6': (0.746, 227.89392),\n",
    " 'epoch 7': (0.744, 265.87624),\n",
    " 'epoch 8': (0.77, 303.85856),\n",
    " 'epoch 9': (0.762, 341.84088),\n",
    " 'epoch 10': (0.792, 379.82320000000004),\n",
    " 'epoch 11': (0.794, 417.80552),\n",
    " 'epoch 12': (0.796, 455.78784),\n",
    " 'epoch 13': (0.79, 493.77016000000003),\n",
    " 'epoch 14': (0.798, 531.75248),\n",
    " 'epoch 15': (0.794, 569.7348000000001),\n",
    " 'epoch 16': (0.79, 607.71712),\n",
    " 'epoch 17': (0.804, 645.69944),\n",
    " 'epoch 18': (0.798, 683.68176),\n",
    " 'epoch 19': (0.798, 721.66408),\n",
    " 'epoch 20': (0.798, 759.6464000000001)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Batch 64\n",
    "\n",
    "{'epoch 1': (0.114, 32.13364),\n",
    " 'epoch 2': (0.384, 64.26728),\n",
    " 'epoch 3': (0.556, 96.40092),\n",
    " 'epoch 4': (0.608, 128.53456),\n",
    " 'epoch 5': (0.662, 160.6682),\n",
    " 'epoch 6': (0.662, 192.80184),\n",
    " 'epoch 7': (0.698, 224.93547999999998),\n",
    " 'epoch 8': (0.726, 257.06912),\n",
    " 'epoch 9': (0.75, 289.20276),\n",
    " 'epoch 10': (0.744, 321.3364),\n",
    " 'epoch 11': (0.766, 353.47004),\n",
    " 'epoch 12': (0.786, 385.60368),\n",
    " 'epoch 13': (0.792, 417.73732),\n",
    " 'epoch 14': (0.8, 449.87095999999997),\n",
    " 'epoch 15': (0.802, 482.0046),\n",
    " 'epoch 16': (0.816, 514.13824),\n",
    " 'epoch 17': (0.808, 546.27188),\n",
    " 'epoch 18': (0.816, 578.40552),\n",
    " 'epoch 19': (0.81, 610.53916),\n",
    " 'epoch 20': (0.814, 642.6728)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Batch 128\n",
    "\n",
    "{'epoch 1': (0.106, 28.799135),\n",
    " 'epoch 2': (0.11, 57.59827),\n",
    " 'epoch 3': (0.408, 86.39740499999999),\n",
    " 'epoch 4': (0.486, 115.19654),\n",
    " 'epoch 5': (0.558, 143.995675),\n",
    " 'epoch 6': (0.604, 172.79480999999998),\n",
    " 'epoch 7': (0.612, 201.593945),\n",
    " 'epoch 8': (0.65, 230.39308),\n",
    " 'epoch 9': (0.666, 259.192215),\n",
    " 'epoch 10': (0.676, 287.99135),\n",
    " 'epoch 11': (0.696, 316.790485),\n",
    " 'epoch 12': (0.722, 345.58961999999997),\n",
    " 'epoch 13': (0.72, 374.388755),\n",
    " 'epoch 14': (0.728, 403.18789),\n",
    " 'epoch 15': (0.742, 431.987025),\n",
    " 'epoch 16': (0.742, 460.78616),\n",
    " 'epoch 17': (0.758, 489.585295),\n",
    " 'epoch 18': (0.76, 518.38443),\n",
    " 'epoch 19': (0.76, 547.183565),\n",
    " 'epoch 20': (0.766, 575.9827)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Batch 256\n",
    "\n",
    "{'epoch 1': (0.004, 26.683749999999996),\n",
    " 'epoch 2': (0.084, 53.36749999999999),\n",
    " 'epoch 3': (0.1, 80.05124999999998),\n",
    " 'epoch 4': (0.108, 106.73499999999999),\n",
    " 'epoch 5': (0.204, 133.41875),\n",
    " 'epoch 6': (0.25, 160.10249999999996),\n",
    " 'epoch 7': (0.41, 186.78624999999997),\n",
    " 'epoch 8': (0.486, 213.46999999999997),\n",
    " 'epoch 9': (0.546, 240.15374999999997),\n",
    " 'epoch 10': (0.558, 266.8375),\n",
    " 'epoch 11': (0.57, 293.52124999999995),\n",
    " 'epoch 12': (0.602, 320.2049999999999),\n",
    " 'epoch 13': (0.608, 346.88874999999996),\n",
    " 'epoch 14': (0.614, 373.57249999999993),\n",
    " 'epoch 15': (0.624, 400.25624999999997),\n",
    " 'epoch 16': (0.648, 426.93999999999994),\n",
    " 'epoch 17': (0.67, 453.6237499999999),\n",
    " 'epoch 18': (0.68, 480.30749999999995),\n",
    " 'epoch 19': (0.69, 506.9912499999999),\n",
    " 'epoch 20': (0.698, 533.675)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Batch 512\n",
    "\n",
    "{'epoch 1': (0.05, 24.98459),\n",
    " 'epoch 2': (0.09, 49.96918),\n",
    " 'epoch 3': (0.104, 74.95377),\n",
    " 'epoch 4': (0.108, 99.93836),\n",
    " 'epoch 5': (0.138, 124.92295),\n",
    " 'epoch 6': (0.218, 149.90754),\n",
    " 'epoch 7': (0.238, 174.89213),\n",
    " 'epoch 8': (0.288, 199.87672),\n",
    " 'epoch 9': (0.276, 224.86131),\n",
    " 'epoch 10': (0.272, 249.8459),\n",
    " 'epoch 11': (0.32, 274.83049),\n",
    " 'epoch 12': (0.404, 299.81508),\n",
    " 'epoch 13': (0.462, 324.79967),\n",
    " 'epoch 14': (0.454, 349.78426),\n",
    " 'epoch 15': (0.5, 374.76885),\n",
    " 'epoch 16': (0.532, 399.75344),\n",
    " 'epoch 17': (0.52, 424.73803000000004),\n",
    " 'epoch 18': (0.542, 449.72262),\n",
    " 'epoch 19': (0.556, 474.70721000000003),\n",
    " 'epoch 20': (0.546, 499.6918)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
