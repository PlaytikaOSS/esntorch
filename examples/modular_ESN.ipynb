{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESN for NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired from : https://huggingface.co/transformers/custom_datasets.html#tok-ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install datasets==1.7.0\n",
    "# !pip install transformers==4.10.3\n",
    "# !pip install seqeval\n",
    "# !pip install pytorch-crf==0.7.2\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ conda install -c conda-forge nodejs\n",
    "$ jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "$ jupyter nbextension enable --py widgetsnbextension\n",
    "$ jupyter lab clean\n",
    "Reload web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "sys.path.insert(0, os.path.abspath(\"../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19241/2821795470.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "from functools import reduce\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "from transformers import BatchEncoding\n",
    "from transformers.data.data_collator import DataCollatorWithPadding, DataCollatorForTokenClassification\n",
    "from datasets import load_metric\n",
    "\n",
    "#from ax import optimize\n",
    "#from ax.plot.contour import plot_contour\n",
    "#from ax.plot.trace import optimization_trace_single_method\n",
    "#from ax.service.managed_loop import optimize\n",
    "#from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "# from ax.utils.tutorials.cnn_utils import load_mnist, train, evaluate, CNN\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import src.models.reservoir as res\n",
    "import src.models.learning_algo as la\n",
    "import src.models.merging_strategy as ms\n",
    "import src.models.esn as esn\n",
    "import src.models.baseline as bs\n",
    "from src.utils.matrix import partial_merging\n",
    "# from src.data.trec import *\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #torch.device('cpu') #\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = '/opt/matterhorn/Data/NER/' #/raid/home/jeremiec/Data/persuasive_essays/output.csv'\n",
    "RESULTS_PATH = '/opt/matterhorn/Data/NER/results'\n",
    "\n",
    "CACHE_DIR = \"../\" #'/opt/matterhorn/Data/NER/datasets' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to get BatchEncoding as batch type, like with DataCollatorWithPadding\n",
    "class CustomDataCollator(DataCollatorForTokenClassification):\n",
    "    def __init__(self, *args, **k_args):\n",
    "        super().__init__(*args, **k_args)\n",
    "        \n",
    "    def torch_call(self, features):\n",
    "        \n",
    "        to_pad = ['offset_mapping', 'original_labels']\n",
    "        padding_token = [[0, 0], -100]\n",
    "        \n",
    "        features_ = [{k: v for k, v in e.items() if k not in to_pad} for e in features]\n",
    "        batch = super().torch_call(features_)\n",
    "        \n",
    "        # Do the padding of our custom field manually as the collator doesn't do it by default\n",
    "        padding_size = len(batch[\"input_ids\"][0])\n",
    "        \n",
    "        for field, pad_tok in zip(to_pad, padding_token):\n",
    "            field_l = [e[field] for e in features]\n",
    "            field_padding_l = [[pad_tok]*(padding_size - actual_len) for actual_len in [len(x) for x in field_l]]\n",
    "            field_l = [field_l[i] + field_padding_l[i] for i in range(len(field_l))]\n",
    "            batch[field] = torch.tensor(field_l, dtype=torch.int64) \n",
    "        \n",
    "        return batch\n",
    "        \n",
    "    def __call__(self, features):\n",
    "        batch = BatchEncoding(super().__call__(features))\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stolen from https://huggingface.co/transformers/custom_datasets.html\n",
    "def encode_tags(batch, padding_label=-100):\n",
    "    \n",
    "    # tags, encodings\n",
    "    \n",
    "    labels = batch['original_labels']\n",
    "    encoded_labels = []\n",
    "    for doc_labels, doc_offset in zip(labels, batch['offset_mapping']):\n",
    "        # create an empty array of `padding_label`\n",
    "        doc_enc_labels = np.ones(len(doc_offset),dtype=int) * padding_label\n",
    "        arr_offset = np.array(doc_offset)\n",
    "\n",
    "        # set labels whose first offset position is 0 and the second is not 0\n",
    "        doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
    "        encoded_labels.append(doc_enc_labels.tolist())\n",
    "\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename correct column as 'labels': depends on the dataset you load\n",
    "\n",
    "def load_and_enrich_dataset(dataset_name, split, tokenizer, cache_dir):\n",
    "    \n",
    "    dataset = load_dataset(dataset_name, split=split, cache_dir=cache_dir)\n",
    "    \n",
    "    # d = pd.read_csv(\"toy_dataset.csv\")\n",
    "    # d.sentences = d.sentences.apply(lambda x: x[2:-2].split(\"', '\"))\n",
    "    # d.labels = d.labels.apply(lambda l: [int(x) for x in l[1:-1].split(\", \")])\n",
    "    # d.columns = [\"tokens\", \"ner_tags\"]\n",
    "    # dataset = Dataset.from_pandas(d, split=\"train\").train_test_split(test_size=0.2)\n",
    "    \n",
    "    def tokenize_ner(batch):\n",
    "        # HACKING MODE ACTIVATED (Remove 0's entities)\n",
    "        #mask = [np.argwhere(n).flatten().tolist() for n in batch[\"ner_tags\"]]\n",
    "        #batch['tokens'] = [[t[i] for i in m] for t,m in zip(batch['tokens'], mask) if len(m) > 0 ]\n",
    "        #batch['ner_tags'] = [[n[i] for i in m] for n,m in zip(batch['ner_tags'], mask) if len(m) > 0]\n",
    "        \n",
    "        # Simplify labels\n",
    "        #batch[\"ner_tags\"] = [[int(x in [1, 2]) for x in l] for l in batch[\"ner_tags\"]]\n",
    "        \n",
    "        batch_tokenized = tokenizer(batch['tokens'], truncation=True, padding=False, is_split_into_words=True, return_offsets_mapping=True)\n",
    "        batch_tokenized[\"lengths\"] = [ len(sample) for sample in batch_tokenized[\"input_ids\"] ]\n",
    "        batch_tokenized[\"original_labels\"] = batch[\"ner_tags\"]\n",
    "        \n",
    "        batch_tokenized[\"labels\"] = encode_tags(batch_tokenized, padding_label=-100)\n",
    "\n",
    "        return batch_tokenized\n",
    "    \n",
    "    # dataset = dataset.remove_columns(['id', 'chunk_tags', 'pos_tags']) # comment if toy dataset\n",
    "    dataset = dataset.map(tokenize_ner, batched=True)\n",
    "    \n",
    "    # EITHER\n",
    "    # dataset = dataset.remove_columns(['ner_tags', 'tokens']) # comment if toy dataset\n",
    "    # OR\n",
    "    dataset.set_format(type=None, columns=['input_ids', 'labels', 'original_labels', 'lengths', 'offset_mapping'])\n",
    "    # IS STRICTLY NECESSARY FOR THE DATALOADER TO WORK\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (../conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198576e9f56646f88f244666d57e066f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3a6d52857d446c81b300efaee8d9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814ce78da3fc4aafb181ba5e33260913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased', padding=True, truncation=True)\n",
    "\n",
    "full_dataset = load_and_enrich_dataset('conll2003', split=None, tokenizer=tokenizer, cache_dir=CACHE_DIR)\n",
    "#full_dataset = full_dataset.sort(\"lengths\")  # BE CAREFUL: we are not sorting the offset mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14041, 3453)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_dataset['train']), len(full_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_tags(full_dataset['train'][:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a, b in zip(tokenizer.convert_ids_to_tokens(full_dataset['train'][0]['input_ids']),  encode_tags(full_dataset['train'][: 1])[0]):\n",
    "#     print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For \"ner_tags\":\n",
    "\n",
    "#### 82.5% of the true dataset labels are 0. \n",
    "\n",
    "#### 84.8% when adding the [CLS] + [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For \"pos_tags\":\n",
    "\n",
    "#### 13.7% of the true dataset labels are 0 when adding the [CLS] + [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for x in full_dataset[\"train\"][\"labels\"]:\n",
    "    l.extend(x[:])\n",
    "for x in full_dataset[\"validation\"][\"labels\"]:\n",
    "    l.extend(x[:])\n",
    "for x in full_dataset[\"test\"][\"labels\"]:\n",
    "    l.extend(x[:])\n",
    "    \n",
    "l = np.array(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing labels '2' and '9' for \"pos_tags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = pd.DataFrame(l)\n",
    "l2 = l2[l2[0] != -100]\n",
    "cross_entropy_weight = (1/l2.value_counts(normalize=True).sort_index()).values\n",
    "cross_entropy_weight = torch.Tensor(cross_entropy_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.2025,  29.9650,  43.1151,  32.3306,  56.9788,  28.3155, 180.3818,\n",
       "         59.5452, 175.5492])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-100,    0,    1,    2,    3,    4,    5,    6,    7,    8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0      250660\n",
       "-100    144074\n",
       " 5       10645\n",
       " 1       10059\n",
       " 3        9323\n",
       " 2        6991\n",
       " 4        5290\n",
       " 7        5062\n",
       " 8        1717\n",
       " 6        1671\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(l)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_labels = np.max(l)+1\n",
    "nb_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of 0 in the dataset: 56.27%\n"
     ]
    }
   ],
   "source": [
    "print(f\"percentage of 0 in the dataset: {100*(l == 0).sum()/len(l):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create modular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, model_name='bert-base-uncased', device=torch.device('cpu')):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.model = BertModel.from_pretrained(self.model_name, output_hidden_states=True)\n",
    "        self.device = device\n",
    "        self.model.to(self.device).eval()\n",
    "        #print('BERT model downloaded:', model_name)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # method 1: dynamic embedding\n",
    "            # batch_tkn = batch[\"input_ids\"].to(self.device)\n",
    "            batch = batch.to(self.device)\n",
    "            batch_emb = self.model(batch[\"input_ids\"], batch[\"attention_mask\"])[0]\n",
    "\n",
    "        return batch_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModularESN(nn.Module):\n",
    "    \n",
    "    def __init__(self, reservoir_dim, output_size, device):\n",
    "        super(ModularESN, self).__init__()\n",
    "\n",
    "        self.reservoir_dim = reservoir_dim\n",
    "        \n",
    "        self.embedding = EmbeddingLayer(model_name='bert-base-uncased', device=device)\n",
    "        self.reservoir = nn.RNN(input_size=768, hidden_size=reservoir_dim,\n",
    "                                num_layers=1, nonlinearity='tanh', bias=True,\n",
    "                                batch_first=True, dropout=0, bidirectional=False)\n",
    "        self.output_linear = nn.Linear(in_features=reservoir_dim, out_features=output_size)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \n",
    "        embedded_input = self.embedding(batch)\n",
    "        reservoir_states, _ = self.reservoir(embedded_input)\n",
    "        \n",
    "        print('\\n')\n",
    "        print('states', reservoir_states.shape)\n",
    "        print('lengths', batch[\"lengths\"].shape)\n",
    "        print('labels', batch[\"labels\"].shape)\n",
    "        \n",
    "        flattened_states = reservoir_states.reshape((-1, self.reservoir_dim))\n",
    "        flattened_labels = batch[\"labels\"].reshape((-1))\n",
    "        \n",
    "        # Mask for padding, SEP, CLS and subtokens\n",
    "        mask = (flattened_labels != -100) & (flattened_labels != -200)\n",
    "        \n",
    "        filtered_states = flattened_states[mask]\n",
    "        filtered_labels = flattened_labels[mask]\n",
    "        filtered_lengths = data[\"lengths\"] - (data[\"labels\"] == -100).sum(axis=1)\n",
    "        \n",
    "        filtered_outputs = self.output_linear(filtered_states)\n",
    "        \n",
    "        print('\\n')\n",
    "        print('filtered_outputs', filtered_outputs.shape)\n",
    "        print('filtered_lengths', filtered_lengths.shape)\n",
    "        print('filtered_labels', filtered_labels.shape)\n",
    "        \n",
    "        return filtered_outputs, filtered_lengths, filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "dataloader_d = {}\n",
    "\n",
    "for k, v in full_dataset.items():\n",
    "    dataloader_d[k] = torch.utils.data.DataLoader(v, batch_size=128, shuffle=True, collate_fn=CustomDataCollator(tokenizer, label_pad_token_id=-200))  # NB: Used to be = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = ModularESN(reservoir_dim=1000, output_size=nb_labels, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(cross_entropy_weight)\n",
    "criterion.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef1e48787434bc492ebc6668eafed35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=110.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1801, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1801])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2072, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2072])\n",
      "\n",
      "\n",
      "states torch.Size([128, 52, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 52])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2031, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2031])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1994, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1994])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1903, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1903])\n",
      "\n",
      "\n",
      "states torch.Size([128, 57, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 57])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1782, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1782])\n",
      "\n",
      "\n",
      "states torch.Size([128, 73, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 73])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1634, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1634])\n",
      "\n",
      "\n",
      "states torch.Size([128, 56, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 56])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1685, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1685])\n",
      "\n",
      "\n",
      "states torch.Size([128, 73, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 73])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1789, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1789])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1995, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1995])\n",
      "\n",
      "\n",
      "states torch.Size([128, 75, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 75])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1875, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1875])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1866, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1866])\n",
      "\n",
      "\n",
      "states torch.Size([128, 59, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 59])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1886, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1886])\n",
      "\n",
      "\n",
      "states torch.Size([128, 74, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 74])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1909, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1909])\n",
      "\n",
      "\n",
      "states torch.Size([128, 77, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 77])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1837, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1837])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1825, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1825])\n",
      "\n",
      "\n",
      "states torch.Size([128, 62, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 62])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1685, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1685])\n",
      "\n",
      "\n",
      "states torch.Size([128, 52, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 52])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2059, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2059])\n",
      "\n",
      "\n",
      "states torch.Size([128, 63, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 63])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1657, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1657])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1879, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1879])\n",
      "[1,    20] loss: 2.075\n",
      "\n",
      "\n",
      "states torch.Size([128, 72, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 72])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1615, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1615])\n",
      "\n",
      "\n",
      "states torch.Size([128, 59, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 59])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1626, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1626])\n",
      "\n",
      "\n",
      "states torch.Size([128, 56, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 56])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1858, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1858])\n",
      "\n",
      "\n",
      "states torch.Size([128, 71, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 71])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2114, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2114])\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2057, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2057])\n",
      "\n",
      "\n",
      "states torch.Size([128, 56, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 56])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2038, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2038])\n",
      "\n",
      "\n",
      "states torch.Size([128, 53, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 53])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1750, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1750])\n",
      "\n",
      "\n",
      "states torch.Size([128, 68, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 68])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2009, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2009])\n",
      "\n",
      "\n",
      "states torch.Size([128, 52, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 52])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1994, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1994])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1853, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1853])\n",
      "\n",
      "\n",
      "states torch.Size([128, 63, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 63])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1656, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1656])\n",
      "\n",
      "\n",
      "states torch.Size([128, 83, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 83])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1683, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1683])\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2029, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2029])\n",
      "\n",
      "\n",
      "states torch.Size([128, 78, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 78])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1800, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1800])\n",
      "\n",
      "\n",
      "states torch.Size([128, 55, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 55])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1890, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1890])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1785, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1785])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1950, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1950])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1918, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1918])\n",
      "\n",
      "\n",
      "states torch.Size([128, 57, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 57])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1889, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1889])\n",
      "\n",
      "\n",
      "states torch.Size([128, 74, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 74])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1706, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1706])\n",
      "[1,    40] loss: 1.912\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1820, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1820])\n",
      "\n",
      "\n",
      "states torch.Size([128, 61, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 61])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1921, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1921])\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2063, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2063])\n",
      "\n",
      "\n",
      "states torch.Size([128, 62, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 62])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1879, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1879])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1874, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1874])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1763, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1763])\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1711, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1711])\n",
      "\n",
      "\n",
      "states torch.Size([128, 57, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 57])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1777, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1777])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1782, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1782])\n",
      "\n",
      "\n",
      "states torch.Size([128, 73, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 73])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1800, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1800])\n",
      "\n",
      "\n",
      "states torch.Size([128, 51, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 51])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1481, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1481])\n",
      "\n",
      "\n",
      "states torch.Size([128, 53, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 53])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1799, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1799])\n",
      "\n",
      "\n",
      "states torch.Size([128, 89, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 89])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2051, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2051])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1639, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1639])\n",
      "\n",
      "\n",
      "states torch.Size([128, 70, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 70])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2076, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2076])\n",
      "\n",
      "\n",
      "states torch.Size([128, 56, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 56])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1800, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1800])\n",
      "\n",
      "\n",
      "states torch.Size([128, 74, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 74])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1889, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1889])\n",
      "\n",
      "\n",
      "states torch.Size([128, 69, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 69])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1940, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1940])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1808, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1808])\n",
      "\n",
      "\n",
      "states torch.Size([128, 92, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 92])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1833, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1833])\n",
      "[1,    60] loss: 1.808\n",
      "\n",
      "\n",
      "states torch.Size([128, 78, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 78])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1721, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1721])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1975, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1975])\n",
      "\n",
      "\n",
      "states torch.Size([128, 87, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 87])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1778, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1778])\n",
      "\n",
      "\n",
      "states torch.Size([128, 77, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 77])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1830, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1830])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1988, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1988])\n",
      "\n",
      "\n",
      "states torch.Size([128, 63, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 63])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1667, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1667])\n",
      "\n",
      "\n",
      "states torch.Size([128, 56, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 56])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1764, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1764])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2027, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2027])\n",
      "\n",
      "\n",
      "states torch.Size([128, 55, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 55])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2003, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2003])\n",
      "\n",
      "\n",
      "states torch.Size([128, 57, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 57])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2053, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2053])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1826, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1826])\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1805, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1805])\n",
      "\n",
      "\n",
      "states torch.Size([128, 69, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 69])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1906, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1906])\n",
      "\n",
      "\n",
      "states torch.Size([128, 56, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 56])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1663, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1663])\n",
      "\n",
      "\n",
      "states torch.Size([128, 56, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 56])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1784, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1784])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1952, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1952])\n",
      "\n",
      "\n",
      "states torch.Size([128, 64, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 64])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1998, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1998])\n",
      "\n",
      "\n",
      "states torch.Size([128, 76, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 76])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1986, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1986])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2002, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2002])\n",
      "\n",
      "\n",
      "states torch.Size([128, 84, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 84])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2057, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2057])\n",
      "[1,    80] loss: 1.724\n",
      "\n",
      "\n",
      "states torch.Size([128, 62, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 62])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1920, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1920])\n",
      "\n",
      "\n",
      "states torch.Size([128, 72, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 72])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2004, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2004])\n",
      "\n",
      "\n",
      "states torch.Size([128, 73, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 73])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1846, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1846])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1916, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1916])\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1880, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1880])\n",
      "\n",
      "\n",
      "states torch.Size([128, 75, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 75])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1903, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1903])\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1919, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1919])\n",
      "\n",
      "\n",
      "states torch.Size([128, 80, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 80])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1990, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1990])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1924, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1924])\n",
      "\n",
      "\n",
      "states torch.Size([128, 63, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 63])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1948, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1948])\n",
      "\n",
      "\n",
      "states torch.Size([128, 57, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 57])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1661, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1661])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1920, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1920])\n",
      "\n",
      "\n",
      "states torch.Size([128, 72, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 72])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1869, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1869])\n",
      "\n",
      "\n",
      "states torch.Size([128, 64, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 64])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1775, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1775])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1905, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1905])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2024, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2024])\n",
      "\n",
      "\n",
      "states torch.Size([128, 72, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 72])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1752, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1752])\n",
      "\n",
      "\n",
      "states torch.Size([128, 52, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 52])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1648, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1648])\n",
      "\n",
      "\n",
      "states torch.Size([128, 61, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 61])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1882, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1882])\n",
      "\n",
      "\n",
      "states torch.Size([128, 57, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 57])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1640, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1640])\n",
      "[1,   100] loss: 1.670\n",
      "\n",
      "\n",
      "states torch.Size([128, 57, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 57])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1857, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1857])\n",
      "\n",
      "\n",
      "states torch.Size([128, 72, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 72])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1716, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1716])\n",
      "\n",
      "\n",
      "states torch.Size([128, 173, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 173])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1818, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1818])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1790, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1790])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1674, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1674])\n",
      "\n",
      "\n",
      "states torch.Size([128, 64, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 64])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1691, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1691])\n",
      "\n",
      "\n",
      "states torch.Size([128, 59, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 59])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1880, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1880])\n",
      "\n",
      "\n",
      "states torch.Size([128, 56, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 56])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1910, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1910])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1916, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1916])\n",
      "\n",
      "\n",
      "states torch.Size([89, 50, 1000])\n",
      "lengths torch.Size([89])\n",
      "labels torch.Size([89, 50])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1168, 9])\n",
      "filtered_lengths torch.Size([89])\n",
      "filtered_labels torch.Size([1168])\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b64300723b456091dcb8f519b5cb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=110.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "states torch.Size([128, 73, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 73])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2063, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2063])\n",
      "\n",
      "\n",
      "states torch.Size([128, 52, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 52])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1916, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1916])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1895, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1895])\n",
      "\n",
      "\n",
      "states torch.Size([128, 63, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 63])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2022, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2022])\n",
      "\n",
      "\n",
      "states torch.Size([128, 62, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 62])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1846, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1846])\n",
      "\n",
      "\n",
      "states torch.Size([128, 52, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 52])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1696, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1696])\n",
      "\n",
      "\n",
      "states torch.Size([128, 59, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 59])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1693, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1693])\n",
      "\n",
      "\n",
      "states torch.Size([128, 57, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 57])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1914, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1914])\n",
      "\n",
      "\n",
      "states torch.Size([128, 59, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 59])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2107, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2107])\n",
      "\n",
      "\n",
      "states torch.Size([128, 75, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 75])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1667, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1667])\n",
      "\n",
      "\n",
      "states torch.Size([128, 59, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 59])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1763, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1763])\n",
      "\n",
      "\n",
      "states torch.Size([128, 64, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 64])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1947, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1947])\n",
      "\n",
      "\n",
      "states torch.Size([128, 64, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 64])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1631, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1631])\n",
      "\n",
      "\n",
      "states torch.Size([128, 61, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 61])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1879, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1879])\n",
      "\n",
      "\n",
      "states torch.Size([128, 50, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 50])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1836, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1836])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1811, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1811])\n",
      "\n",
      "\n",
      "states torch.Size([128, 62, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 62])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1957, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1957])\n",
      "\n",
      "\n",
      "states torch.Size([128, 69, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 69])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1879, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1879])\n",
      "\n",
      "\n",
      "states torch.Size([128, 74, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 74])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1796, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1796])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1602, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1602])\n",
      "[2,    20] loss: 1.584\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1778, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1778])\n",
      "\n",
      "\n",
      "states torch.Size([128, 64, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 64])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1935, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1935])\n",
      "\n",
      "\n",
      "states torch.Size([128, 72, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 72])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1871, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1871])\n",
      "\n",
      "\n",
      "states torch.Size([128, 64, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 64])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1814, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1814])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2062, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2062])\n",
      "\n",
      "\n",
      "states torch.Size([128, 62, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 62])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1819, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1819])\n",
      "\n",
      "\n",
      "states torch.Size([128, 84, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 84])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2214, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2214])\n",
      "\n",
      "\n",
      "states torch.Size([128, 173, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 173])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1905, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1905])\n",
      "\n",
      "\n",
      "states torch.Size([128, 74, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 74])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1903, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1903])\n",
      "\n",
      "\n",
      "states torch.Size([128, 49, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 49])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1833, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1833])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1813, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1813])\n",
      "\n",
      "\n",
      "states torch.Size([128, 65, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 65])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1884, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1884])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1839, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1839])\n",
      "\n",
      "\n",
      "states torch.Size([128, 87, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 87])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2080, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2080])\n",
      "\n",
      "\n",
      "states torch.Size([128, 78, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 78])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1870, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1870])\n",
      "\n",
      "\n",
      "states torch.Size([128, 57, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 57])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1835, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1835])\n",
      "\n",
      "\n",
      "states torch.Size([128, 71, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 71])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1988, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1988])\n",
      "\n",
      "\n",
      "states torch.Size([128, 53, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 53])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1660, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1660])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1990, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1990])\n",
      "\n",
      "\n",
      "states torch.Size([128, 52, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 52])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1725, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1725])\n",
      "[2,    40] loss: 1.577\n",
      "\n",
      "\n",
      "states torch.Size([128, 59, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 59])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1669, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1669])\n",
      "\n",
      "\n",
      "states torch.Size([128, 61, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 61])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1931, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1931])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2001, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2001])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1880, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1880])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1658, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1658])\n",
      "\n",
      "\n",
      "states torch.Size([128, 55, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 55])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1588, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1588])\n",
      "\n",
      "\n",
      "states torch.Size([128, 61, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 61])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2111, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2111])\n",
      "\n",
      "\n",
      "states torch.Size([128, 72, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 72])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1768, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1768])\n",
      "\n",
      "\n",
      "states torch.Size([128, 63, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 63])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1945, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1945])\n",
      "\n",
      "\n",
      "states torch.Size([128, 64, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 64])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1880, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1880])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1902, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1902])\n",
      "\n",
      "\n",
      "states torch.Size([128, 63, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 63])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1757, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1757])\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1729, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1729])\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1896, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1896])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1746, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1746])\n",
      "\n",
      "\n",
      "states torch.Size([128, 72, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 72])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1943, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1943])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1974, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1974])\n",
      "\n",
      "\n",
      "states torch.Size([128, 62, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 62])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2013, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2013])\n",
      "\n",
      "\n",
      "states torch.Size([128, 63, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 63])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2020, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2020])\n",
      "\n",
      "\n",
      "states torch.Size([128, 63, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 63])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1681, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1681])\n",
      "[2,    60] loss: 1.554\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1775, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1775])\n",
      "\n",
      "\n",
      "states torch.Size([128, 92, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 92])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1937, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1937])\n",
      "\n",
      "\n",
      "states torch.Size([128, 77, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 77])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1999, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1999])\n",
      "\n",
      "\n",
      "states torch.Size([128, 56, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 56])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1944, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1944])\n",
      "\n",
      "\n",
      "states torch.Size([128, 52, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 52])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1847, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1847])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1758, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1758])\n",
      "\n",
      "\n",
      "states torch.Size([128, 69, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 69])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1886, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1886])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1933, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1933])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1840, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1840])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1991, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1991])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1817, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1817])\n",
      "\n",
      "\n",
      "states torch.Size([128, 72, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 72])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1921, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1921])\n",
      "\n",
      "\n",
      "states torch.Size([128, 74, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 74])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1847, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1847])\n",
      "\n",
      "\n",
      "states torch.Size([128, 89, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 89])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1990, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1990])\n",
      "\n",
      "\n",
      "states torch.Size([128, 75, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 75])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1926, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1926])\n",
      "\n",
      "\n",
      "states torch.Size([128, 78, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 78])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1843, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1843])\n",
      "\n",
      "\n",
      "states torch.Size([128, 73, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 73])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1862, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1862])\n",
      "\n",
      "\n",
      "states torch.Size([128, 53, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 53])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1714, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1714])\n",
      "\n",
      "\n",
      "states torch.Size([128, 62, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 62])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1990, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1990])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1778, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1778])\n",
      "[2,    80] loss: 1.530\n",
      "\n",
      "\n",
      "states torch.Size([128, 57, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 57])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1740, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1740])\n",
      "\n",
      "\n",
      "states torch.Size([128, 80, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 80])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1862, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1862])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1715, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1715])\n",
      "\n",
      "\n",
      "states torch.Size([128, 72, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 72])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1778, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1778])\n",
      "\n",
      "\n",
      "states torch.Size([128, 70, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 70])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1994, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1994])\n",
      "\n",
      "\n",
      "states torch.Size([128, 76, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 76])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1760, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1760])\n",
      "\n",
      "\n",
      "states torch.Size([128, 53, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 53])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1652, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1652])\n",
      "\n",
      "\n",
      "states torch.Size([128, 77, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 77])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1703, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1703])\n",
      "\n",
      "\n",
      "states torch.Size([128, 63, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 63])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1984, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1984])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1728, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1728])\n",
      "\n",
      "\n",
      "states torch.Size([128, 60, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 60])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1892, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1892])\n",
      "\n",
      "\n",
      "states torch.Size([128, 74, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 74])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1752, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1752])\n",
      "\n",
      "\n",
      "states torch.Size([128, 72, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 72])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1768, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1768])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2021, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2021])\n",
      "\n",
      "\n",
      "states torch.Size([128, 56, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 56])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1545, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1545])\n",
      "\n",
      "\n",
      "states torch.Size([128, 53, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 53])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1804, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1804])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([2171, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([2171])\n",
      "\n",
      "\n",
      "states torch.Size([128, 54, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 54])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1863, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1863])\n",
      "\n",
      "\n",
      "states torch.Size([128, 56, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 56])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1691, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1691])\n",
      "\n",
      "\n",
      "states torch.Size([128, 48, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 48])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1803, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1803])\n",
      "[2,   100] loss: 1.468\n",
      "\n",
      "\n",
      "states torch.Size([128, 57, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 57])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1866, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1866])\n",
      "\n",
      "\n",
      "states torch.Size([128, 55, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 55])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1690, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1690])\n",
      "\n",
      "\n",
      "states torch.Size([128, 58, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 58])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1840, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1840])\n",
      "\n",
      "\n",
      "states torch.Size([128, 73, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 73])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1881, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1881])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1981, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1981])\n",
      "\n",
      "\n",
      "states torch.Size([128, 66, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 66])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1889, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1889])\n",
      "\n",
      "\n",
      "states torch.Size([128, 67, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 67])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1981, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1981])\n",
      "\n",
      "\n",
      "states torch.Size([128, 63, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 63])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1865, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1865])\n",
      "\n",
      "\n",
      "states torch.Size([128, 61, 1000])\n",
      "lengths torch.Size([128])\n",
      "labels torch.Size([128, 61])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1759, 9])\n",
      "filtered_lengths torch.Size([128])\n",
      "filtered_labels torch.Size([1759])\n",
      "\n",
      "\n",
      "states torch.Size([89, 83, 1000])\n",
      "lengths torch.Size([89])\n",
      "labels torch.Size([89, 83])\n",
      "\n",
      "\n",
      "filtered_outputs torch.Size([1215, 9])\n",
      "filtered_lengths torch.Size([89])\n",
      "filtered_labels torch.Size([1215])\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dataloader_d[\"train\"]), total=len(dataloader_d['train'])):\n",
    "        \n",
    "        data.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, lengths, labels = model(data)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:   \n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.968     0.464     0.627       973\n",
      "           1      0.282     0.453     0.348        53\n",
      "           2      0.188     0.585     0.284        41\n",
      "           3      0.158     0.340     0.216        47\n",
      "           4      0.114     0.385     0.175        26\n",
      "           5      0.237     0.548     0.331        42\n",
      "           6      0.111     0.700     0.192        10\n",
      "           7      0.099     0.400     0.158        20\n",
      "           8      0.028     1.000     0.055         3\n",
      "\n",
      "    accuracy                          0.466      1215\n",
      "   macro avg      0.243     0.542     0.265      1215\n",
      "weighted avg      0.813     0.466     0.555      1215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels.cpu().numpy(), outputs.argmax(dim=1).cpu().numpy(), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** NEW ***\n",
    "# Recreate the dataloaders with shuffle=False in order to ba able to compute the predictions correcly\n",
    "# Otherwise, everything is re-shuffled every time we iterate through the dataloader!!!\n",
    "dataloader_d = {}\n",
    "\n",
    "for k, v in full_dataset.items():\n",
    "    dataloader_d[k] = torch.utils.data.DataLoader(v, batch_size=128, shuffle=False, collate_fn=CustomDataCollator(tokenizer, label_pad_token_id=-100))  # NB: Used to be = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebb3d8b453740aaa4506739fbcff5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73175/194952985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0margmax_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1055\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions_l = []\n",
    "labels_l = []\n",
    "\n",
    "for data in tqdm(dataloader_d[\"test\"]):\n",
    "    with torch.no_grad():\n",
    "        data.to(device)\n",
    "        \n",
    "        labels = data[\"labels\"].cpu().numpy()\n",
    "        lengths = data[\"lengths\"]\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(data, lengths)\n",
    "\n",
    "        argmax_output = outputs.cpu().numpy().argmax(axis=1)\n",
    "        \n",
    "        begin_i = 0 \n",
    "        for i,l in enumerate(lengths):\n",
    "            predictions_l.append(argmax_output[begin_i:begin_i+l])\n",
    "            labels_l.append(labels[i][:l])\n",
    "            begin_i += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outside of the loop\n",
    "if self.merging_strategy.merging_strategy is None :\n",
    "    predictions_l = [np.array(x) for x in predictions_l]\n",
    "else:\n",
    "    predictions_l = np.concatenate([x for x in predictions_l], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62e3902474c4f8db3be5691a8eb8351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preds is a list of tensors: 1 prediction tensor per batch\n",
    "\n",
    "preds_l = ESN.predict(dataloader_d[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_l = []\n",
    "\n",
    "for b in dataloader_d[\"test\"]:\n",
    "    batch_labels = b[\"original_labels\"].cpu().detach().numpy()\n",
    "    for s_labels in batch_labels:\n",
    "        labels_l.append(s_labels[s_labels != -100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4) B-LOC (5), I-LOC (6) B-MISC (7), I-MISC (8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = [\n",
    "            [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(preds_l, labels_l)\n",
    "        ]\n",
    "\n",
    "true_labels = [\n",
    "            [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(preds_l, labels_l)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = metric.compute(predictions=true_predictions, references=true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.7968659315147998,\n",
       "  'recall': 0.8231414868105515,\n",
       "  'f1': 0.8097906222353288,\n",
       "  'number': 1668},\n",
       " 'MISC': {'precision': 0.6449375866851595,\n",
       "  'recall': 0.6623931623931624,\n",
       "  'f1': 0.6535488404778637,\n",
       "  'number': 702},\n",
       " 'ORG': {'precision': 0.6913783635365184,\n",
       "  'recall': 0.7579771222155328,\n",
       "  'f1': 0.7231476163124642,\n",
       "  'number': 1661},\n",
       " 'PER': {'precision': 0.920049968769519,\n",
       "  'recall': 0.9109461966604824,\n",
       "  'f1': 0.9154754505904288,\n",
       "  'number': 1617},\n",
       " 'overall_precision': 0.7790658029321513,\n",
       " 'overall_recall': 0.8091359773371105,\n",
       " 'overall_f1': 0.7938162237276359,\n",
       " 'overall_accuracy': 0.9656293743943146}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.85      0.85      0.85      1668\n",
      "      B-MISC       0.78      0.69      0.73       702\n",
      "       B-ORG       0.81      0.80      0.80      1661\n",
      "       B-PER       0.95      0.93      0.94      1617\n",
      "       I-LOC       0.74      0.64      0.69       257\n",
      "      I-MISC       0.60      0.61      0.60       216\n",
      "       I-ORG       0.81      0.82      0.81       835\n",
      "       I-PER       0.98      0.97      0.97      1156\n",
      "           O       0.99      0.99      0.99     38323\n",
      "\n",
      "    accuracy                           0.97     46435\n",
      "   macro avg       0.83      0.81      0.82     46435\n",
      "weighted avg       0.97      0.97      0.97     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flattened_preds = []\n",
    "for l in true_predictions:\n",
    "    for p in l:\n",
    "        flattened_preds.append(p)\n",
    "        \n",
    "flattened_labels = []\n",
    "for l in true_labels:\n",
    "    for p in l:\n",
    "        flattened_labels.append(p)\n",
    "        \n",
    "print(classification_report(flattened_labels, flattened_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
