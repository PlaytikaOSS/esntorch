

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>esntorch.core package &mdash; esntorch 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> esntorch
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../esn_description.html">Echo State Networks for Text Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">Architecture</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">esntorch</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>esntorch.core package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/source/esntorch.core.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="esntorch-core-package">
<h1>esntorch.core package<a class="headerlink" href="#esntorch-core-package" title="Permalink to this headline">¶</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</section>
<section id="module-esntorch.core.baseline">
<span id="esntorch-core-baseline-module"></span><h2>esntorch.core.baseline module<a class="headerlink" href="#module-esntorch.core.baseline" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.baseline.Baseline">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.baseline.</span></span><span class="sig-name descname"><span class="pre">Baseline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_algo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">merging_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lexicon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">device(type='cpu')</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.baseline.Baseline" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#esntorch.core.esn.EchoStateNetwork" title="esntorch.core.esn.EchoStateNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">esntorch.core.esn.EchoStateNetwork</span></code></a></p>
<p>Implements the baseline algorithms (logistic regression (LR), deep neural net (DNN), etc.).
Here, The baseline algorithms are simply ESNs where the reservoir step is omitted.
In other words, a baseline consists of the combination of a merging strategy and a learning algorithm.
This class inherits from EchoStateNetwork</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embedding_weights</strong> (<em>torch.Tensor</em>) – Embedding matrix.</p></li>
<li><p><strong>input_dim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>learning_algo</strong> (<em>src.models.learning_algo.RidgeRegression</em><em>, </em><em>src.models.learning_algo.LogisticRegression</em>) – Learning algorithm used to learn the targets from the reservoir (merged) states.</p></li>
<li><p><strong>criterion</strong> (<em>torch.nn.modules.loss</em>) – Criterion used to compute the loss between tagets and predictions (only if leaning_algo ≠ RidgeRegression).</p></li>
<li><p><strong>optimizer</strong> (<em>torch.optim</em>) – Optimizer used in the gradient descent method (only if leaning_algo ≠ RidgeRegression).</p></li>
<li><p><strong>merging_strategy</strong> (<em>src.models.merging_strategy.MergingStrategy</em>) – Merging strategy used to merge the sucessive reservoir states.</p></li>
<li><p><strong>bidirectional</strong> (<em>bool</em>) – Flag for bi-directionality.</p></li>
<li><p><strong>seed</strong> (<em>torch._C.Generator</em>) – Random seed.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="esntorch.core.baseline.Baseline.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#esntorch.core.baseline.Baseline.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.baseline.CustomBaseline">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.baseline.</span></span><span class="sig-name descname"><span class="pre">CustomBaseline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reservoir_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tanh'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_algo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">merging_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lexicon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">device(type='cpu')</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.baseline.CustomBaseline" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#esntorch.core.esn.EchoStateNetwork" title="esntorch.core.esn.EchoStateNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">esntorch.core.esn.EchoStateNetwork</span></code></a></p>
<p>Implements the Custom Baseline, which consists of an embedding layer (EMB)
followed by a fully connected layer (FC) followed by a learning algorithm (LA)
(e.g., Ridge regression).
Note that the FC layer is not trained.
Custom RR-Baseline = EMB + FC + LA
This class inherits from EchoStateNetwork</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embedding_weights</strong> (<em>torch.Tensor</em>) – Embedding matrix.</p></li>
<li><p><strong>input_dim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>reservoir_dim</strong> (<em>int</em>) – Dimension of the hidden layer onto which the embedded inputs are projected.</p></li>
<li><p><strong>input_scaling</strong> (<em>float</em>) – Bounds used for the uniform random generation of the input weights.</p></li>
<li><p><strong>bias_scaling</strong> (<em>float</em>) – Bounds used for the uniform random generation of the bias weights.</p></li>
<li><p><strong>activation_function</strong> (<em>str</em>) – Activation function of the reservoir cells (‘tanh’ by default).</p></li>
<li><p><strong>learning_algo</strong> (<em>Union</em><em>[</em><em>src.models.learning_algo.RidgeRegression</em><em>, </em><em>src.models.learning_algo.LogisticRegression</em><em>,</em><em>...</em><em>]</em>) – Learning algorithm used to learn the association between the reservoir (merged) states and the targets.</p></li>
<li><p><strong>criterion</strong> (<em>torch.nn.modules.loss</em>) – Criterion used to compute the loss between tagets and predictions (only if leaning_algo ≠ RidgeRegression).</p></li>
<li><p><strong>optimizer</strong> (<em>torch.optim</em>) – Optimizer used in the gradient descent method (only if leaning_algo ≠ RidgeRegression).</p></li>
<li><p><strong>merging_strategy</strong> (<em>src.models.merging_strategy.MergingStrategy</em>) – Merging strategy used to merge the sucessive reservoir states.</p></li>
<li><p><strong>bidirectional</strong> (<em>bool</em>) – Flag for bi-directionality.</p></li>
<li><p><strong>seed</strong> (<em>torch._C.Generator</em>) – Random seed.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="esntorch.core.baseline.CustomBaseline.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#esntorch.core.baseline.CustomBaseline.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-esntorch.core.deep_esn">
<span id="esntorch-core-deep-esn-module"></span><h2>esntorch.core.deep_esn module<a class="headerlink" href="#module-esntorch.core.deep_esn" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.deep_esn.DeepEchoStateNetwork">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.deep_esn.</span></span><span class="sig-name descname"><span class="pre">DeepEchoStateNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nb_reservoirs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distributions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reservoir_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_scalings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_scalings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">means</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparsities</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spectral_radii</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaking_rates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_functions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seeds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_algo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">merging_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lexicon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.deep_esn.DeepEchoStateNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#esntorch.core.esn.EchoStateNetwork" title="esntorch.core.esn.EchoStateNetwork"><code class="xref py py-class docutils literal notranslate"><span class="pre">esntorch.core.esn.EchoStateNetwork</span></code></a></p>
<p>Implements the Deep Echo State Network (BS) per se.
An Deep ESN consists of the combination of many reservoir, a merging strategy and a learning algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nb_reservoirs</strong> (<em>int</em>) – Number of reservoirs composing the deep reservoir.</p></li>
<li><p><strong>embedding_weights</strong> (<em>torch.Tensor</em>) – Embedding matrix for the <em>first</em> reservoir layer only (a priori).</p></li>
<li><p><strong>distributions</strong> (<em>list of str</em>) – List of distributions (‘uniform’ or ‘gaussian’ of the reservoirs)</p></li>
<li><p><strong>reservoir_dims</strong> (<em>list of int</em>) – List of reservoir dimensions.</p></li>
<li><p><strong>bias_scalings</strong> (<em>list of float</em>) – List of bias scaling values of the reservoirs: bounds used for the bias random generation.</p></li>
<li><p><strong>input_scalings</strong> (<em>list of float</em>) – List of input scaling values applied only in the case of uniform reservoirs, and ignored otherwise:
bounds used for the input weights random generation.</p></li>
<li><p><strong>means</strong> (<em>list of float</em>) – List of means applied only in the case of Gaussian reservoirs, and ignored otherwise:
Mean for Gaussian generation of reservoirs weights.</p></li>
<li><p><strong>stds</strong> (<em>list of float</em>) – List of standard deviations applied only in the case of Gaussian reservoirs, and ignored otherwise:
Standard deviations for Gaussian generation of reservoirs weights.</p></li>
<li><p><strong>sparsities</strong> (<em>list of float</em>) – List of sparsity values of the reservoirs (between 0 and 1)</p></li>
<li><p><strong>spectral_radii</strong> (<em>list of float</em>) – Spectral radii of the reservoirs’ weights.
Should theoretically be below 1, but slightly above 1 works in practice.</p></li>
<li><p><strong>leaking_rates</strong> (<em>list of float</em>) – Leaking rate of teh reservoir (between 0 and 1).
Determines the amount of last state and current input involved in the current state updating.</p></li>
<li><p><strong>activation_functions</strong> (<em>list of builtin_function_or_method</em>) – Activation function of the reservoir cells (tanh by default).</p></li>
<li><p><strong>seeds</strong> (<em>list of int</em>) – Random seeds.</p></li>
<li><p><strong>learning_algo</strong> (<em>src.models.learning_algo.RidgeRegression</em><em>, </em><em>src.models.learning_algo.LogisticRegression</em>) – Learning algorithm used to learn the targets from the reservoir (merged) states.</p></li>
<li><p><strong>criterion</strong> (<em>torch.nn.modules.loss</em>) – Criterion used to compute the loss between tagets and predictions (only if leaning_algo ≠ RidgeRegression).</p></li>
<li><p><strong>optimizer</strong> (<em>torch.optim</em>) – Optimizer used in the gradient descent method (only if leaning_algo ≠ RidgeRegression).</p></li>
<li><p><strong>merging_strategy</strong> (<em>src.models.merging_strategy.MergingStrategy</em>) – Merging strategy used to merge the sucessive reservoir states.</p></li>
<li><p><strong>bidirectional</strong> (<em>bool</em>) – Flag for bi-directionality.</p></li>
<li><p><strong>seed</strong> (<em>torch._C.Generator</em>) – Random seed.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="esntorch.core.deep_esn.DeepEchoStateNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#esntorch.core.deep_esn.DeepEchoStateNetwork.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-esntorch.core.deep_reservoir">
<span id="esntorch-core-deep-reservoir-module"></span><h2>esntorch.core.deep_reservoir module<a class="headerlink" href="#module-esntorch.core.deep_reservoir" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.deep_reservoir.DeepReservoir">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.deep_reservoir.</span></span><span class="sig-name descname"><span class="pre">DeepReservoir</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nb_reservoirs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distributions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reservoir_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_scalings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_scalings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">means</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparsities</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spectral_radii</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaking_rates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_functions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seeds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.deep_reservoir.DeepReservoir" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Implements a deep reservoir, to be used in the context of a deep echo state network (DeepESN).
Parameters are self-explanatory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nb_reservoirs</strong> (<em>int</em>) – Number of reservoirs composing the deep reservoir.</p></li>
<li><p><strong>embedding_weights</strong> (<em>torch.Tensor</em>) – Embedding matrix for the <em>first</em> reservoir layer only (a priori).</p></li>
<li><p><strong>distributions</strong> (<em>list of str</em>) – List of distributions (‘uniform’ or ‘gaussian’ of the reservoirs)</p></li>
<li><p><strong>reservoir_dims</strong> (<em>list of int</em>) – List of reservoir dimensions.</p></li>
<li><p><strong>bias_scalings</strong> (<em>list of float</em>) – List of bias scaling values of the reservoirs: bounds used for the bias random generation.</p></li>
<li><p><strong>input_scalings</strong> (<em>list of float</em>) – List of input scaling values applied only in the case of uniform reservoirs, and ignored otherwise:
bounds used for the input weights random generation.</p></li>
<li><p><strong>means</strong> (<em>list of float</em>) – List of means applied only in the case of Gaussian reservoirs, and ignored otherwise:
Mean for Gaussian generation of reservoirs weights.</p></li>
<li><p><strong>stds</strong> (<em>list of float</em>) – List of standard deviations applied only in the case of Gaussian reservoirs, and ignored otherwise:
Standard deviations for Gaussian generation of reservoirs weights.</p></li>
<li><p><strong>sparsities</strong> (<em>list of float</em>) – List of sparsity values of the reservoirs (between 0 and 1)</p></li>
<li><p><strong>spectral_radii</strong> (<em>list of float</em>) – Spectral radii of the reservoirs’ weights.
Should theoretically be below 1, but slightly above 1 works in practice.</p></li>
<li><p><strong>leaking_rates</strong> (<em>list of float</em>) – Leaking rate of teh reservoir (between 0 and 1).
Determines the amount of last state and current input involved in the current state updating.</p></li>
<li><p><strong>activation_functions</strong> (<em>list of builtin_function_or_method</em>) – Activation function of the reservoir cells (tanh by default).</p></li>
<li><p><strong>seeds</strong> (<em>list of int</em>) – Random seeds.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.deep_reservoir.DeepReservoir.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.deep_reservoir.DeepReservoir.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements forwards pass, i.e., processing of a batch of input texts by the successive reservoirs.
This method uses the forward method of each reservoir</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>torch.Tensor</em>) – 2D input tensor (max_length x batch_size).
A batch of input texts is a 2D tensor.
Each tensor column represents a text - given as the sequence of its word indices.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>concatenated_states, lengths</strong> – concatenated_states : 3D tensor (batch_size x max_length x reservoir_dim).
Reservoir states obtained after processing the batch of inputs into the successive reservoirs.
lengths : 1D tensor (batch_size).
Lengths of input texts in the batch.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor, torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.deep_reservoir.DeepReservoir.reverse_forward">
<span class="sig-name descname"><span class="pre">reverse_forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_tokens</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.deep_reservoir.DeepReservoir.reverse_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the concatenated states obtained after processing the batch of texts in the successive reservoirs
in the inverse order.</p>
<p>It applies the forward on the reversed tokens in a batch
(it will not inverse the padding tokens).</p>
<p>The original lengths of the padded token sentences must be supplied.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_tokens</strong> (<em>torch.Tensor</em>) – 2D tensor of the batch tokens.</p></li>
<li><p><strong>lengths</strong> (<em>torch.Tensor</em>) – 1D tensor, the token sentences true lengths.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>reversed_concatenated_states</strong> – 3D tensor of the batch of states of the reversed input, with the padded states in the correct place.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="esntorch.core.deep_reservoir.DeepReservoir.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#esntorch.core.deep_reservoir.DeepReservoir.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.deep_reservoir.DeepReservoir.warm_up">
<span class="sig-name descname"><span class="pre">warm_up</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">warm_up_sequence</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.deep_reservoir.DeepReservoir.warm_up" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs forward pass of an input sequence.
For each reservoir, set its last reservoir state as its new initial state.
This method uses the warm_up method of each reservoir</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>warm_up_sequence</strong> (<em>torch.Tensor</em>) – 1D tensor: word indices of the warm up sentence.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-esntorch.core.esn">
<span id="esntorch-core-esn-module"></span><h2>esntorch.core.esn module<a class="headerlink" href="#module-esntorch.core.esn" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.esn.EchoStateNetwork">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.esn.</span></span><span class="sig-name descname"><span class="pre">EchoStateNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reservoir_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparsity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spectral_radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaking_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tanh'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_algo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">merging_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bidirectional</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lexicon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'esn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">device(type='cpu')</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.esn.EchoStateNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Implements the Echo State Network (ESN) per se.
An ESN consists of the combination of a reservoir, a merging strategy and a learning algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embedding_weights</strong> (<em>torch.Tensor</em>) – Embedding matrix.</p></li>
<li><p><strong>distribution</strong> (<em>str</em>) – Distribution of the reservoir: ‘uniform’ or ‘gaussian’</p></li>
<li><p><strong>input_dim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>reservoir_dim</strong> (<em>int</em>) – Reservoir dimension.</p></li>
<li><p><strong>bias_scaling</strong> (<em>float</em>) – Bias scaling: bounds used for the bias random generation.</p></li>
<li><p><strong>sparsity</strong> (<em>float</em>) – Sparsity of the reservoir ((between 0 and 1))</p></li>
<li><p><strong>spectral_radius</strong> (<em>float</em>) – Spectral radius of the reservoir weights.
Should theoretically be below 1, but slightly above 1 works in practice.</p></li>
<li><p><strong>leaking_rate</strong> (<em>float</em><em> (</em><em>between 0 and 1</em><em>)</em>) – Leaking rate of teh reservoir (between 0 and 1).
Determines the amount of last state and current input involved in the current state updating.</p></li>
<li><p><strong>activation_function</strong> (<em>str</em>) – Activation function of the reservoir cells (‘tanh’ by default).</p></li>
<li><p><strong>input_scaling</strong> (<em>float</em>) – Input scaling: bounds used for the input weights random generation (if distribution == ‘uniform’).</p></li>
<li><p><strong>mean</strong> (<em>float</em>) – Mean of the input and reservoir weights (if distribution == ‘gaussian’)</p></li>
<li><p><strong>std</strong> (<em>float</em>) – Standard deviation of the input and reservoir weights (if distribution == ‘gaussian’)</p></li>
<li><p><strong>learning_algo</strong> (<em>src.models.learning_algo.RidgeRegression</em><em>, </em><em>src.models.learning_algo.LogisticRegression</em>) – Learning algorithm used to learn the targets from the reservoir (merged) states.</p></li>
<li><p><strong>criterion</strong> (<em>torch.nn.modules.loss</em>) – Criterion used to compute the loss between tagets and predictions (only if leaning_algo ≠ RidgeRegression).</p></li>
<li><p><strong>optimizer</strong> (<em>torch.optim</em>) – Optimizer used in the gradient descent method (only if leaning_algo ≠ RidgeRegression).</p></li>
<li><p><strong>merging_strategy</strong> (<em>src.models.merging_strategy.MergingStrategy</em>) – Merging strategy used to merge the sucessive reservoir states.</p></li>
<li><p><strong>bidirectional</strong> (<em>bool</em>) – Flag for bi-directionality.</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – The ESN can be used in different modes in order to implement kinds of models
(classical ESN, baselines, etc.):
If mode==’esn’, the classical ESN is implemented (EMB + RESERVOIR + LA).
If mode==’linear_layer’, the Custom Baseline is implemented (EMB + LINEAR_LAYER + LA).
If mode==’no_layer’, the Simple Baseline is implemented (EMB + LA).</p></li>
<li><p><strong>seed</strong> (<em>torch._C.Generator</em>) – Random seed.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.esn.EchoStateNetwork.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iter_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.esn.EchoStateNetwork.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fits the ESN on the training set. Fitting is performed according to:
1) a learning algorithm;
2) a merging strategy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>torchtext.data.iterator.Iterator</em>) – Training dataset.</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – Number of traning epochs (only if leaning_algo ≠ RidgeRegression)</p></li>
<li><p><strong>iter_steps</strong> (<em>int</em>) – Number of traning steps after which loss is recorded (only if leaning_algo ≠ RidgeRegression).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>loss_l</strong> – None if closed-form solution used.
list of losses if gradient descent used.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>None, list</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.esn.EchoStateNetwork.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.esn.EchoStateNetwork.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the ESN on a dataset (train or test).
Returns the list of prediction labels. If true labels are known, returns the accuracy also.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dataloader</strong> (<em>torchtext.data.iterator.Iterator</em>) – Test dataset.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>predictions_l, accuracy</strong> – List of prediction labels and accuracy.
If true labels are not known, returns None for accuracy.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list, float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="esntorch.core.esn.EchoStateNetwork.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#esntorch.core.esn.EchoStateNetwork.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.esn.EchoStateNetwork.warm_up">
<span class="sig-name descname"><span class="pre">warm_up</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">warm_up_sequence</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.esn.EchoStateNetwork.warm_up" title="Permalink to this definition">¶</a></dt>
<dd><p>Passes a warm up sequence to the ESN and set the warm state as the new initial state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>warm_up_sequence</strong> (<em>torch.Tensor</em>) – 1D tensor: word indices of the warm up sentence.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-esntorch.core.learning_algo">
<span id="esntorch-core-learning-algo-module"></span><h2>esntorch.core.learning_algo module<a class="headerlink" href="#module-esntorch.core.learning_algo" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.DeepNN">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.learning_algo.</span></span><span class="sig-name descname"><span class="pre">DeepNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layers_l</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.DeepNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Implements a deep neural network whose layers are specified by a list.
Make sure the the dimensions of the first and last layers
correspond to the input and output dimensions, respectively.
Example: A 2-hidden layer NN with 50 neurons in each layer and input / output dimensions of 300 / 3
is implemented as follows: layers_l = [300, 50, 50, 3]; model = DeepNN(layers_l).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>layers_l</strong> (<em>list</em>) – List of integers representing the number on neurons in each layer.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.DeepNN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">activation</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.DeepNN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements forward pass (with ReLU activation function for the hidden layers).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>activation</strong> (<em>torch.Tensor</em>) – Activation values of the input layer neurons: (batch size x input dim).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>activation</strong> – Activation values of the output layer neurons: (batch size x output dim).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.DeepNN.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#esntorch.core.learning_algo.DeepNN.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.GaussianNBLayer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.learning_algo.</span></span><span class="sig-name descname"><span class="pre">GaussianNBLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">priors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var_smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.GaussianNBLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Implements Gaussian Naive Bayes algorithm from scikit learn.
Don’t use it with negative data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sklearn.naive_bayes.GaussianNB</strong> (<em>Same parameters as those of</em>) – </p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.GaussianNBLayer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.GaussianNBLayer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides fit method of GaussianNB.
Simply convert torch tensors into numpy and apply original fit method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Tensor of features (gathered by rows).</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – Tensor of targets (gathered by rows).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.LinearSVCLayer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.learning_algo.</span></span><span class="sig-name descname"><span class="pre">LinearSVCLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'squared_hinge'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dual</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ovr'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_intercept</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intercept_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.LinearSVCLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Implements Linear Support Vector Machine Classifier from scikit learn.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sklearn.svm.LinearSVC</strong> (<em>Same parameters as those of</em>) – </p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.LinearSVCLayer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.LinearSVCLayer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides fit method of GaussianNB.
Simply convert torch tensors into numpy and apply original fit method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Tensor of features (gathered by rows).</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – Tensor of targets (gathered by rows).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.LogisticRegression">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.learning_algo.</span></span><span class="sig-name descname"><span class="pre">LogisticRegression</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.LogisticRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Implements classical logistic regression as a 1-layer neural network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>output_dim</strong> (<em>int</em>) – Output dimension.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.LogisticRegression.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.LogisticRegression.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – Tensor of features (gathered by rows).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>outputs</strong> – Tensor of outputs (gathered by row).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.LogisticRegression.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#esntorch.core.learning_algo.LogisticRegression.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.LogisticRegression2">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.learning_algo.</span></span><span class="sig-name descname"><span class="pre">LogisticRegression2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'l2'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dual</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_intercept</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">intercept_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'liblinear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l1_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.LogisticRegression2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Implements Logistic Regression from scikit learn.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sklearn.linear_model.LogisticRegression</strong> (<em>Same parameters as those of</em>) – </p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.LogisticRegression2.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.LogisticRegression2.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides fit method of LogisticRegression.
Simply convert torch tensors into numpy and apply original fit method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Tensor of features (gathered by rows).</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – Tensor of targets (gathered by rows).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.MultinomialNBLayer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.learning_algo.</span></span><span class="sig-name descname"><span class="pre">MultinomialNBLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fit_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_prior</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.MultinomialNBLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Implements Multinomial Naive Bayes algorithm from scikit learn.
Don’t use it with negative data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sklearn.naive_bayes.MultinomialNB</strong> (<em>Same parameters as those of</em>) – </p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.MultinomialNBLayer.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.MultinomialNBLayer.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides fit method of MultinomialNB.
Simply convert torch tensors into numpy and apply original fit method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Tensor of features (gathered by rows).</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – Tensor of targets (gathered by rows).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.RandomForest">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.learning_algo.</span></span><span class="sig-name descname"><span class="pre">RandomForest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gini'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_weight_fraction_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaf_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ccp_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.RandomForest" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Implements Random Forest algorithm from scikit learn:</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sklearn.ensemble.RandomForestClassifier</strong> (<em>Same parameters as those of</em>) – </p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.RandomForest.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.RandomForest.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides fit method of RandomForestClassifier.
Simply convert torch tensors into numpy and apply original fit method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Tensor of features (gathered by rows).</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – Tensor of targets (gathered by rows).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.RidgeRegression">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.learning_algo.</span></span><span class="sig-name descname"><span class="pre">RidgeRegression</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.RidgeRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Implements Ridge regression via its closed form solution:
$$ beta = (X^T X + lambda I)^{-1} X^T y $$
Works for multi-class problems with target values 0, 1, 2, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>alpha</strong> (<em>float</em>) – Regularization parameter.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.RidgeRegression.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.RidgeRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the closed form solution of the Ridge regression and update self.weights with the learned weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>torch.Tensor</em>) – Tensor of features (gathered by rows).</p></li>
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – Tensor of targets (gathered by rows).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.RidgeRegression.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.learning_algo.RidgeRegression.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes predictions using weights obtained by fit method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>torch.Tensor</em>) – Tensor of features (gathered by rows).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>outputs</strong> – Outputs of Ridge regression</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="esntorch.core.learning_algo.RidgeRegression.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#esntorch.core.learning_algo.RidgeRegression.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-esntorch.core.merging_strategy">
<span id="esntorch-core-merging-strategy-module"></span><h2>esntorch.core.merging_strategy module<a class="headerlink" href="#module-esntorch.core.merging_strategy" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.merging_strategy.MergingStrategy">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.merging_strategy.</span></span><span class="sig-name descname"><span class="pre">MergingStrategy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">merging_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lexicon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.merging_strategy.MergingStrategy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Implements various merging strategies - or pooling layers - for grouping successive ESN states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>merging_strategy</strong> (<em>None</em><em>, </em><em>str</em>) – The possible merging strategies are: None, ‘first’, ‘last’, mean’, ‘weighted’, ‘lexicon_weighted’.
None: collects all the ESN states (no merging).
‘first’: takes the first ESN state.
‘last’: takes the last ESN state.
‘mean’: takes the mean of ESN states.
‘weighted’: takes a weighted mean of ESN states.
‘lexicon_weighted’: takes a weighted mean of ESN states, where the words’ weights are given by a lexicon.</p></li>
<li><p><strong>weights</strong> (<em>torch.Tensor</em>) – Weights to be considered for the weighted mean merging strategy.
If weights == None (default), computes attention-like weights.
If weights != None, uses the given weights.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.merging_strategy.MergingStrategy.merge_batch">
<span class="sig-name descname"><span class="pre">merge_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">states_batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">texts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">merging_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.merging_strategy.MergingStrategy.merge_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements the different merging strategies: None, ‘first’, ‘last’, ‘mean’, ‘weighted’.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states_batch</strong> (<em>torch.Tensor</em>) – 3D tensor containing the ESN states: (batch size x max text length x reservoir dim).</p></li>
<li><p><strong>lengths</strong> (<em>torch.Tensor</em>) – 1D tensor containing the length of each text in the batch: (batch size).</p></li>
<li><p><strong>texts</strong> (<em>torch.Tensor</em>) – 2D tensor containing the word indices of the texts in the batch (max text length x batch size).</p></li>
<li><p><strong>merging_strategy</strong> (<em>None</em><em>, </em><em>str</em>) – None, ‘first’, ‘last’, ‘mean’, ‘weighted’.</p></li>
<li><p><strong>weights</strong> (<em>None</em><em>, </em><em>torch.Tensor</em>) – 2D tensor containing the weights for each state (batch size x max text length).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>merged_states</strong> – If merging_strategy is not None, 2D tensor containing the merged states: (batch size x reservoir dim).
If merging_strategy is None, 2D tensor containing all states: (Sum_i len(state_i) x reservoir dim).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-esntorch.core.nbsvm">
<span id="esntorch-core-nbsvm-module"></span><h2>esntorch.core.nbsvm module<a class="headerlink" href="#module-esntorch.core.nbsvm" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="esntorch.core.nbsvm.fit">
<span class="sig-prename descclassname"><span class="pre">esntorch.core.nbsvm.</span></span><span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.nbsvm.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>In case of binary classification task:
- fit 1 model based on features of class 1 vs features of class 2.
In case of N-ary classification task with N&gt;2:
- fit N models based on features of class K vs features of classes 1,2,…,K-1,K+1,…,N, for each K = 1,…,N.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="esntorch.core.nbsvm.nbsvm">
<span class="sig-prename descclassname"><span class="pre">esntorch.core.nbsvm.</span></span><span class="sig-name descname"><span class="pre">nbsvm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.nbsvm.nbsvm" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit a NB-SVM model for a binary classification problem: class_k vs other classes</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="esntorch.core.nbsvm.pr">
<span class="sig-prename descclassname"><span class="pre">esntorch.core.nbsvm.</span></span><span class="sig-name descname"><span class="pre">pr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_i</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.nbsvm.pr" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes feature hat{p} / norm_1(hat{p}) based on whether label y == y_i</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="esntorch.core.nbsvm.pr_not">
<span class="sig-prename descclassname"><span class="pre">esntorch.core.nbsvm.</span></span><span class="sig-name descname"><span class="pre">pr_not</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_i</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.nbsvm.pr_not" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes feature hat{p} / norm_1(hat{p}) based on whether label y != y_i.
This feature is used in the 1-vs-rest version of the algorithm.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="esntorch.core.nbsvm.predict">
<span class="sig-prename descclassname"><span class="pre">esntorch.core.nbsvm.</span></span><span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">models</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.nbsvm.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes predictions based on all one-vs-rest trained models.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="esntorch.core.nbsvm.prepare_datasets">
<span class="sig-prename descclassname"><span class="pre">esntorch.core.nbsvm.</span></span><span class="sig-name descname"><span class="pre">prepare_datasets</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.nbsvm.prepare_datasets" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="module-esntorch.core.reservoir">
<span id="esntorch-core-reservoir-module"></span><h2>esntorch.core.reservoir module<a class="headerlink" href="#module-esntorch.core.reservoir" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.reservoir.GaussianReservoir">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.reservoir.</span></span><span class="sig-name descname"><span class="pre">GaussianReservoir</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reservoir_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparsity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spectral_radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaking_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tanh'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">device(type='cpu')</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.reservoir.GaussianReservoir" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#esntorch.core.reservoir.Reservoir" title="esntorch.core.reservoir.Reservoir"><code class="xref py py-class docutils literal notranslate"><span class="pre">esntorch.core.reservoir.Reservoir</span></code></a></p>
<p>Implements a reservoir generated from a Gaussian distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embedding_weights</strong> (<em>torch.Tensor</em>) – </p></li>
<li><p><strong>input_dim</strong> (<em>int</em>) – </p></li>
<li><p><strong>input_scaling</strong> (<em>float</em>) – </p></li>
<li><p><strong>reservoir_dim</strong> (<em>int</em>) – </p></li>
<li><p><strong>bias_scaling</strong> (<em>float</em>) – </p></li>
<li><p><strong>sparsity</strong> (<em>float</em>) – </p></li>
<li><p><strong>spectral_radius</strong> (<em>float</em>) – </p></li>
<li><p><strong>leaking_rate</strong> (<em>float</em>) – </p></li>
<li><p><strong>mean</strong> (<em>float</em>) – </p></li>
<li><p><strong>std</strong> (<em>float</em>) – </p></li>
<li><p><strong>activation_function</strong> (<em>str</em>) – </p></li>
<li><p><strong>seed</strong> (<em>torch._C.Generator</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="esntorch.core.reservoir.GaussianReservoir.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#esntorch.core.reservoir.GaussianReservoir.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.reservoir.Reservoir">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.reservoir.</span></span><span class="sig-name descname"><span class="pre">Reservoir</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reservoir_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparsity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spectral_radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaking_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tanh'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">device(type='cpu')</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.reservoir.Reservoir" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Implements the reservoir of an echo state network (ESN).
The required parameters are self-explanatory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embedding_weights</strong> (<em>torch.Tensor</em>) – Embedding matrix.</p></li>
<li><p><strong>input_dim</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>reservoir_dim</strong> (<em>int</em>) – Reservoir dimension.</p></li>
<li><p><strong>bias_scaling</strong> (<em>float</em>) – Bias scaling: bounds used for the bias random generation.</p></li>
<li><p><strong>sparsity</strong> (<em>float</em>) – Sparsity of the reservoir ((between 0 and 1))</p></li>
<li><p><strong>spectral_radius</strong> (<em>float</em>) – Spectral radius of the reservoir weights.
Should theoretically be below 1, but slightly above 1 works in practice.</p></li>
<li><p><strong>leaking_rate</strong> (<em>float</em><em> (</em><em>between 0 and 1</em><em>)</em>) – Leaking rate of teh reservoir (between 0 and 1).
Determines the amount of last state and current input involved in the current state updating.</p></li>
<li><p><strong>activation_function</strong> (<em>str</em>) – Activation function of the reservoir cells (‘tanh’ by default).</p></li>
<li><p><strong>seed</strong> (<em>torch._C.Generator</em>) – Random seed.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.reservoir.Reservoir.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'esn'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.reservoir.Reservoir.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements the processing of a batch of input texts into the model.
If mode==’esn’, the model is an ESN (EMB + RESERVOIR + LA).
If mode==’linear_layer’, the model is the Custom Baseline (EMB + LINEAR_LAYER + LA).
if mode==’no_layer’, the model is the Simple Baseline” (EMB + LA).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Union</em><em>[</em><em>transformers.tokenization_utils_base.BatchEncoding</em><em>, </em><em>torch.Tensor</em><em>]</em>) – <p>In the case of a dynamic embedding, like BERT,
batch is a BatchEncoding object output by a Hugging Face tokenizer.
Usually, batch contains different keys, like ‘attention_mask’, ‘input_ids’, ‘labels’, ‘lengths’…
batch[‘input_ids’] is a 2D tensor (batch_size x max_length) of the form:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span><span class="p">([[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2129</span><span class="p">,</span> <span class="mi">2001</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2054</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mi">102</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2073</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mi">102</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
        <span class="o">...</span><span class="p">,</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2054</span><span class="p">,</span> <span class="mi">2001</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">7064</span><span class="p">,</span> <span class="mi">1029</span><span class="p">,</span>  <span class="mi">102</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2054</span><span class="p">,</span> <span class="mi">2024</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">2015</span><span class="p">,</span> <span class="mi">1029</span><span class="p">,</span>  <span class="mi">102</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2073</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">2241</span><span class="p">,</span> <span class="mi">1029</span><span class="p">,</span>  <span class="mi">102</span><span class="p">]])</span>
</pre></div>
</div>
<p>This tensor is composed by the tokenized sentences of the batch stacked horizontally.
In the case of a static embedding, batch is a 2D tensor (batch_size x max_length) of the form:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span><span class="p">([[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2129</span><span class="p">,</span> <span class="mi">2001</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2054</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mi">102</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2073</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mi">102</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
        <span class="o">...</span><span class="p">,</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2054</span><span class="p">,</span> <span class="mi">2001</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">7064</span><span class="p">,</span> <span class="mi">1029</span><span class="p">,</span>  <span class="mi">102</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2054</span><span class="p">,</span> <span class="mi">2024</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">2015</span><span class="p">,</span> <span class="mi">1029</span><span class="p">,</span>  <span class="mi">102</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2073</span><span class="p">,</span> <span class="mi">2003</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">2241</span><span class="p">,</span> <span class="mi">1029</span><span class="p">,</span>  <span class="mi">102</span><span class="p">]])</span>
</pre></div>
</div>
<p>This tensor is composed by the tokenized sentences of the batch stacked horizontally.</p>
</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – ‘esn’ implements foward pass of the ESN (EMB + RESERVOIR + LA).
‘linear_layer’ implements the foward pass of the Custom Baseline (EMB + LINEAR_LAYER + LA).
‘no_layer’ implements the foward pass of the Simple Baseline (EMB + LA).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states, lengths</strong> – See the method _forward_esn() for further details.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor, torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.reservoir.Reservoir.reverse_forward">
<span class="sig-name descname"><span class="pre">reverse_forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'esn'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.reservoir.Reservoir.reverse_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>This function return the reservoir states obtained when the tokens ids
are passed through the reservoir in the inverse order.
It applies the forward on a reversed batch.
Note that it will not inverse the padding tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Union</em><em>[</em><em>transformers.tokenization_utils_base.BatchEncoding</em><em>, </em><em>torch.Tensor</em><em>]</em>) – 3D tensor. See the docstring of the forward method for further description.</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – ‘esn’ implements foward pass of the ESN.
‘linear_layer’ implements the foward pass of the Custom Baseline.
‘no_layer’ implements the foward pass of the Simple Baseline.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>reversed_states</strong> (<em>torch.Tensor</em>) – 3D tensor: batch of states obtained after the processing of the reversed input.
The padded states are kept to their initial locations.</p></li>
<li><p><strong>lengths</strong> (<em>torch.Tensor</em>) – 1D tensor: see the docstring of the forward method for further description.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="esntorch.core.reservoir.Reservoir.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#esntorch.core.reservoir.Reservoir.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="esntorch.core.reservoir.Reservoir.warm_up">
<span class="sig-name descname"><span class="pre">warm_up</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">warm_up_sequence</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.reservoir.Reservoir.warm_up" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs forward pass of an input sequence and set last reservoir state as new initial state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>warm_up_sequence</strong> (<em>torch.Tensor</em>) – 1D tensor: word indices of the warm up sentence.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="esntorch.core.reservoir.UniformReservoir">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">esntorch.core.reservoir.</span></span><span class="sig-name descname"><span class="pre">UniformReservoir</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reservoir_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias_scaling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparsity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spectral_radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">leaking_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tanh'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">device(type='cpu')</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#esntorch.core.reservoir.UniformReservoir" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#esntorch.core.reservoir.Reservoir" title="esntorch.core.reservoir.Reservoir"><code class="xref py py-class docutils literal notranslate"><span class="pre">esntorch.core.reservoir.Reservoir</span></code></a></p>
<p>Implements a reservoir generated from a uniform distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embedding_weights</strong> (<em>torch.Tensor</em>) – </p></li>
<li><p><strong>input_dim</strong> (<em>int</em>) – </p></li>
<li><p><strong>input_scaling</strong> (<em>float</em>) – </p></li>
<li><p><strong>reservoir_dim</strong> (<em>int</em>) – </p></li>
<li><p><strong>bias_scaling</strong> (<em>float</em>) – </p></li>
<li><p><strong>sparsity</strong> (<em>float</em>) – </p></li>
<li><p><strong>spectral_radius</strong> (<em>float</em>) – </p></li>
<li><p><strong>leaking_rate</strong> (<em>float</em>) – </p></li>
<li><p><strong>activation_function</strong> (<em>str</em>) – </p></li>
<li><p><strong>seed</strong> (<em>torch._C.Generator</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="esntorch.core.reservoir.UniformReservoir.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#esntorch.core.reservoir.UniformReservoir.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-esntorch.core">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-esntorch.core" title="Permalink to this headline">¶</a></h2>
</section>
</section>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2021, Playtika Ltd.

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>