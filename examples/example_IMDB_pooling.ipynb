{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a use case example of the ``EsnTorch`` library.\n",
    "It described the implementation of an Echo State Network (ESN)\n",
    "for text classification on the IMDB dataset.\n",
    "\n",
    "The instantiation, training and evaluation of an ESN for text classification\n",
    "is achieved via the following steps:\n",
    "- Import the required modules\n",
    "- Create the dataloaders\n",
    "- Instantiate the ESN by specifying:\n",
    "    - a reservoir\n",
    "    - a loss function\n",
    "    - a learning algorithm\n",
    "- Train the ESN\n",
    "- Training and testing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install huggingface-hub==0.0.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn\n",
    "# !pip install transformers==4.8.2 # !!!\n",
    "# !pip install datasets==1.7.0     # !!! # run !pip install huggingface-hub==0.0.19 before!!!\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current versions:\n",
      "1.0.2\n",
      "2.0.0\n",
      "4.17.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "print(\"Current versions:\")\n",
    "print(sklearn.__version__)\n",
    "print(datasets.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tqdm progress bars (on a terminal):\n",
    "1. `conda install -c conda-forge nodejs`\n",
    "2. `jupyter labextension install @jupyter-widgets/jupyterlab-manager`\n",
    "3. `jupyter nbextension enable --py widgetsnbextension`\n",
    "4. `jupyter lab clean`\n",
    "5. Refresh web page..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment this if library is installed\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "import esntorch.core.reservoir as res\n",
    "import esntorch.core.learning_algo as la\n",
    "import esntorch.core.merging_strategy as ms\n",
    "import esntorch.core.esn as esn\n",
    "import esntorch.utils.embedding as emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New seeds to see if the problem comes from the seed\n",
    "torch.manual_seed(123)\n",
    "np.random.seed(17375)\n",
    "import random\n",
    "random.seed(665)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device and Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions for loading and preparing data\n",
    "\n",
    "def tokenize(sample):\n",
    "    \"\"\"Tokenize sample\"\"\"\n",
    "    \n",
    "    sample = tokenizer(sample['text'], truncation=True, padding=False, return_length=True)\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def load_and_prepare_dataset(dataset_name, split, cache_dir):\n",
    "    \"\"\"\n",
    "    Load dataset from the datasets library of HuggingFace.\n",
    "    Tokenize and add length.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = load_dataset(dataset_name, split=split, cache_dir=CACHE_DIR)\n",
    "    \n",
    "    # Rename label column for tokenization purposes\n",
    "    dataset = dataset.rename_column('label', 'labels')\n",
    "    \n",
    "    # Tokenize data\n",
    "    dataset = dataset.map(tokenize, batched=True)\n",
    "    dataset = dataset.rename_column('length', 'lengths')\n",
    "    # dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels', 'lengths'])\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to cache_dir/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027f2af135004e27a42ffdbc68ecf6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb downloaded and prepared to cache_dir/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8c8409deb94077b5784d63c10d3aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82828e50532840bc8c7a74bd08132f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfc74284f204404ac1be2333e7714fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f30452c805443eac2b3c754e49b2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load and prepare data\n",
    "CACHE_DIR = 'cache_dir/' # put your path here\n",
    "\n",
    "full_dataset = load_and_prepare_dataset('imdb', split=None, cache_dir=CACHE_DIR)\n",
    "\n",
    "# *** JUST FOR NOW ***\n",
    "# full_dataset = full_dataset['train'].train_test_split(test_size=0.1)['test'] # sample 10%\n",
    "# full_dataset = full_dataset.train_test_split(test_size=0.2)\n",
    "# for split in full_dataset.keys():\n",
    "#     full_dataset[split] = full_dataset[split].flatten_indices() # needs this to reset indices\n",
    "# *** JUST FOR NOW ***\n",
    "train_dataset = full_dataset['train'].sort(\"lengths\")\n",
    "test_dataset = full_dataset['test'].sort(\"lengths\")\n",
    "\n",
    "# Create dict of all datasets\n",
    "dataset_d = {\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'lengths'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask', 'lengths'],\n",
       "     num_rows: 25000\n",
       " })}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_features(dataset_d):\n",
    "    \"\"\"Compute tf-idf features for the dataset\"\"\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=4000)\n",
    "    vectorizer.fit(dataset_d['train']['text'])\n",
    "    \n",
    "    tfidf_fts = {}\n",
    "    \n",
    "    for split in dataset_d.keys():\n",
    "        X_tmp = vectorizer.transform(dataset_d[split]['text'])\n",
    "        X_tmp = list(X_tmp.todense())\n",
    "        X_tmp = [np.asarray(row).reshape(-1) for row in X_tmp]\n",
    "        tfidf_fts[split] = X_tmp\n",
    "        \n",
    "        dataset_d[split] = dataset_d[split].add_column(\"additional_fts\", X_tmp)\n",
    "        dataset_d[split].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels', 'lengths', 'additional_fts'])\n",
    "        dataset_d[split] = dataset_d[split].remove_columns(\"text\")\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    return dataset_d, t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84be71028e9c4855ad908a68865eb662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef37f94453364fecbfa90ca85762e0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_d, fts_time = get_tfidf_features(dataset_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'lengths', 'additional_fts'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'lengths', 'additional_fts'],\n",
       "     num_rows: 25000\n",
       " })}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.64738917350769"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'lengths', 'additional_fts'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'lengths', 'additional_fts'],\n",
       "     num_rows: 25000\n",
       " })}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict of dataloaders\n",
    "\n",
    "dataloader_d = {}\n",
    "\n",
    "for k, v in dataset_d.items():\n",
    "    dataloader_d[k] = torch.utils.data.DataLoader(v, batch_size=256, collate_fn=DataCollatorWithPadding(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f9353c016a0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f9353c018b0>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in dataloader_d['train']:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 4000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['additional_fts'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write datasets into files\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# tmp_dir = '/raid/home/jeremiec/Data/tmp'\n",
    "\n",
    "# for split in ['train', 'test']:\n",
    "    \n",
    "#     reviews_l = dataset_d[split]['text']\n",
    "            \n",
    "#     with open(os.path.join(tmp_dir, str(split)+\"_datasets_\"+str(datasets.__version__)+\".txt\"), 'wb') as fh:\n",
    "        \n",
    "#         pickle.dump(reviews_l, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_datasets_1.7.0\n",
      "test_datasets_2.0.0\n",
      "train_datasets_2.0.0\n",
      "train_datasets_1.7.0\n"
     ]
    }
   ],
   "source": [
    "# Compare train/test files for old and new datasets versions\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "imdb_d = {}\n",
    "\n",
    "tmp_dir = '/raid/home/jeremiec/Data/tmp'\n",
    "\n",
    "for file in os.listdir(tmp_dir):\n",
    "    \n",
    "    if file.endswith('txt'):\n",
    "    \n",
    "        filename = os.fsdecode(file)\n",
    "        key = filename[:-4]\n",
    "        print(key)\n",
    "\n",
    "        with open(os.path.join(tmp_dir, filename), 'rb') as fh:\n",
    "\n",
    "            value = pickle.load(fh)\n",
    "\n",
    "        imdb_d[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(imdb_d['train_datasets_1.7.0']):\n",
    "    if t not in imdb_d['train_datasets_2.0.0']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(imdb_d['test_datasets_1.7.0']):\n",
    "    if t not in imdb_d['test_datasets_2.0.0']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The datasets are the same!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2023,  3185,  ...,     0,     0,     0],\n",
       "        [  101,  1045,  2876,  ...,     0,     0,     0],\n",
       "        [  101,  7918, 14674,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2054,  2064,  ...,  1005,  1012,   102],\n",
       "        [  101,  2023,  3185,  ...,  1013,  1028,   102],\n",
       "        [  101,  2023,  3185,  ...,  2156,   999,   102]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "embedding = emb.EmbeddingModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embedding.get_embedding(b)\n",
    "\n",
    "torch.save(x, os.path.join(tmp_dir, \"x_\"+str(datasets.__version__)+\"_\"+str(transformers.__version__)+\".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.load(os.path.join(tmp_dir, \"x_\"+str(datasets.__version__)+\"_\"+str(transformers.__version__)+\".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57, 256, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.load(os.path.join(tmp_dir, \"x_1.7.0_4.8.2.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = torch.load(os.path.join(tmp_dir, \"x_1.7.0_4.17.0.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x2 == x3).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# ESN parameters\n",
    "esn_params = {\n",
    "            'embedding_weights': 'bert-base-uncased', # TEXT.vocab.vectors,\n",
    "            'distribution' : 'gaussian',              # uniform, gaussian\n",
    "            'input_dim' : 768,                        # dim of BERT encoding!\n",
    "            'reservoir_dim' : 1000,\n",
    "            'input_scaling' : 1.0,\n",
    "            'bias_scaling' : 1.0, # can be None\n",
    "            'sparsity' : 0.99,\n",
    "            'spectral_radius' : 0.9,\n",
    "            'leaking_rate': 0.5,\n",
    "            'activation_function' : 'relu',           # 'tanh', relu'\n",
    "            'mean' : 0.0,\n",
    "            'std' : 1.0,\n",
    "            #'learning_algo' : None, # initialzed below\n",
    "            #'criterion' : None,     # initialzed below\n",
    "            #'optimizer' : None,     # initialzed below\n",
    "            'merging_strategy' : 'mean_and_additional_fts', # 'mean_and_additional_fts', # 'mean'\n",
    "            'bidirectional' : False, # True\n",
    "            'device' : device,\n",
    "            'seed' : 42,\n",
    "            'mode': 'no_layer' # 'esn', 'custom_baseline'\n",
    "             }\n",
    "\n",
    "# Instantiate the ESN\n",
    "ESN = esn.EchoStateNetwork(**esn_params)\n",
    "\n",
    "# Define the learning algo of the ESN\n",
    "ESN.learning_algo = la.RidgeRegression(alpha=10)\n",
    "# ESN.learning_algo = la.RidgeRegression2()\n",
    "# ESN.learning_algo = la.LinearSVC()\n",
    "# ESN.learning_algo = la.LogisticRegression2()\n",
    "\n",
    "# Put the ESN on the device (CPU or GPU)\n",
    "ESN = ESN.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Warm up the ESN on 5 sentences\n",
    "nb_sentences = 5\n",
    "\n",
    "for i in range(nb_sentences): \n",
    "    sentence = dataset_d[\"train\"].select([i])\n",
    "    dataloader_tmp = torch.utils.data.DataLoader(sentence, \n",
    "                                                 batch_size=1, \n",
    "                                                 collate_fn=DataCollatorWithPadding(tokenizer))  \n",
    "\n",
    "    for sentence in dataloader_tmp:\n",
    "        ESN.warm_up(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 34.9 s, total: 2min 8s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training the ESN\n",
    "ESN.fit(dataloader_d[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.604"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train predictions and accuracy\n",
    "train_pred, train_acc = ESN.predict(dataloader_d[\"train\"], verbose=False)\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test predictions and accuracy\n",
    "test_pred, test_acc = ESN.predict(dataloader_d[\"test\"], verbose=False)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9019    0.9048    0.9034     12500\n",
      "           1     0.9045    0.9016    0.9030     12500\n",
      "\n",
      "    accuracy                         0.9032     25000\n",
      "   macro avg     0.9032    0.9032    0.9032     25000\n",
      "weighted avg     0.9032    0.9032    0.9032     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test classification report\n",
    "print(classification_report(dataset_d['test']['labels'].tolist(),\n",
    "                            test_pred.tolist(),\n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BERT + tf-idf 4000 (no_layer)\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0     0.9585    0.9464    0.9524     12500\n",
    "           1     0.9471    0.9590    0.9530     12500\n",
    "\n",
    "    accuracy                         0.9527     25000\n",
    "   macro avg     0.9528    0.9527    0.9527     25000\n",
    "weighted avg     0.9528    0.9527    0.9527     25000"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# with TF-IDF of 3000 dim, res dim=1000\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0     0.9558    0.9400    0.9478     12500\n",
    "           1     0.9410    0.9566    0.9487     12500\n",
    "\n",
    "    accuracy                         0.9483     25000\n",
    "   macro avg     0.9484    0.9483    0.9483     25000\n",
    "weighted avg     0.9484    0.9483    0.9483     25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dataset_d['train']['text']\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "X_train = vectorizer.fit_transform(corpus)\n",
    "X_test = vectorizer.transform(dataset_d['test']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearSVC()\n",
    "# model = LogisticRegression(C=2)\n",
    "model = RidgeClassifier(alpha=10)\n",
    "\n",
    "model.fit(X_train, dataset_d['train']['labels'])\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(dataset_d['train']['labels'], y_train_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(dataset_d['test']['labels'], y_test_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
