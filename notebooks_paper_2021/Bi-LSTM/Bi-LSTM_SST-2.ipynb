{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM on SST-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.8.2\n",
    "# !pip install datasets==1.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "from esntorch.utils.embedding import EmbeddingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = '~/Results/Bi-LSTM/Bi-LSTM/sst-2_bilstm-128_10ep_model.pt'\n",
    "RESULTS_FILE = '~/Results/Bi-LSTM/Bi-LSTM/sst-2_bilstm-128_10ep_results.pkl'\n",
    "CACHE_DIR = 'cache_dir/' # put your path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename correct column as 'labels': depends on the dataset you load\n",
    "\n",
    "def load_and_enrich_dataset(*dataset_name, split, cache_dir):\n",
    "    \n",
    "    dataset = load_dataset(*dataset_name, split=split, cache_dir=CACHE_DIR)\n",
    "    \n",
    "    def clean(example):\n",
    "        example['text'] = example['text'].replace('-LRB-', '(').replace('-RRB-', ')').replace(r'\\/', r'/')\n",
    "        return example\n",
    "        \n",
    "    if 'sentence' in dataset.column_names:\n",
    "        dataset = dataset.rename_column('sentence', 'text')\n",
    "        \n",
    "    dataset = dataset.map(clean)\n",
    "    dataset = dataset.rename_column('label', 'labels')\n",
    "    \n",
    "    dataset = dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding=False), batched=True)\n",
    "    \n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "    def add_lengths(sample):\n",
    "        sample[\"lengths\"] = sum(sample[\"input_ids\"] != 0)\n",
    "        return sample\n",
    "    \n",
    "    dataset = dataset.map(add_lengths, batched=False)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CACHE_DIR = 'cache_dir/' # put your path here\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_dataset = load_and_enrich_dataset('glue', 'sst2', split='train', cache_dir=CACHE_DIR).sort(\"lengths\")\n",
    "val_dataset = load_and_enrich_dataset('glue', 'sst2', split='validation', cache_dir=CACHE_DIR).sort(\"lengths\")\n",
    "test_dataset = load_and_enrich_dataset('gpt3mix/sst2', split='test', cache_dir=CACHE_DIR).sort(\"lengths\")\n",
    "def revert(example):\n",
    "    example['labels'] = np.abs(example['labels'] - 1) # revert labels of test set\n",
    "    return example\n",
    "test_dataset = test_dataset.map(revert) # revert labels of test set\n",
    "\n",
    "\n",
    "dataset_d = {\n",
    "    'full_train': train_dataset,\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset,\n",
    "    'test': test_dataset\n",
    "    }\n",
    "\n",
    "dataloader_d = {}\n",
    "for k, v in dataset_d.items():\n",
    "    dataloader_d[k] = torch.utils.data.DataLoader(v, batch_size=256, collate_fn=DataCollatorWithPadding(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_train': Dataset({\n",
       "     features: ['attention_mask', 'idx', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 67349\n",
       " }),\n",
       " 'train': Dataset({\n",
       "     features: ['attention_mask', 'idx', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 67349\n",
       " }),\n",
       " 'val': Dataset({\n",
       "     features: ['attention_mask', 'idx', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 872\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 1821\n",
       " })}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim,\n",
    "                 hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = EmbeddingModel('bert-base-uncased', device)\n",
    "        \n",
    "        # recurrent hidden layers (LSTM)\n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        # fully connected output layer (fc)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        packed_embedded = self.dropout(self.embedding.get_embedding(batch))        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)      \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "            \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = len(set(dataset_d['full_train']['labels'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 768\n",
    "HIDDEN_DIM = 128 # 256 was default\n",
    "OUTPUT_DIM = output_dim # 1 (binary) or output_dim (*** multiclass ***)\n",
    "N_LAYERS = 1 # 2 was default\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "# PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "model = RNN(EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 920,066 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion\n",
    "# criterion = nn.BCEWithLogitsLoss() # binary\n",
    "criterion = nn.CrossEntropyLoss() # *** multiclass ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put model and criterion to device\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary accuracy\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    # round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds)) # thresholding output neuron\n",
    "    correct = (rounded_preds == y).float()            # convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** multiclass ***\n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    \n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    \n",
    "    return correct.sum().item() / torch.FloatTensor([y.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions_raw = model(batch)\n",
    "                        \n",
    "        predictions = predictions_raw.squeeze(1)\n",
    "                \n",
    "        loss = criterion(predictions, batch['labels'])\n",
    "        \n",
    "        # acc = binary_accuracy(predictions, batch.label)        # *** binary *** \n",
    "        acc = categorical_accuracy(predictions, batch['labels']) # *** multiclass ***\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch['labels'])\n",
    "            \n",
    "            # acc = binary_accuracy(predictions, batch.label)        # *** binary ***\n",
    "            acc = categorical_accuracy(predictions, batch['labels']) # *** multiclass ***\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    \n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 2m 1s\n",
      "\tTrain Loss: 0.352 | Train Acc: 84.34%\n",
      "\t Val. Loss: 0.441 |  Val. Acc: 85.04%\n",
      "Epoch: 02 | Epoch Time: 1m 59s\n",
      "\tTrain Loss: 0.300 | Train Acc: 87.13%\n",
      "\t Val. Loss: 0.653 |  Val. Acc: 81.05%\n",
      "Epoch: 03 | Epoch Time: 1m 59s\n",
      "\tTrain Loss: 0.267 | Train Acc: 88.74%\n",
      "\t Val. Loss: 0.620 |  Val. Acc: 79.51%\n",
      "Epoch: 04 | Epoch Time: 2m 0s\n",
      "\tTrain Loss: 0.244 | Train Acc: 89.89%\n",
      "\t Val. Loss: 0.490 |  Val. Acc: 85.91%\n",
      "Epoch: 05 | Epoch Time: 2m 0s\n",
      "\tTrain Loss: 0.221 | Train Acc: 91.01%\n",
      "\t Val. Loss: 0.491 |  Val. Acc: 86.50%\n",
      "Epoch: 06 | Epoch Time: 1m 58s\n",
      "\tTrain Loss: 0.205 | Train Acc: 91.73%\n",
      "\t Val. Loss: 0.607 |  Val. Acc: 81.58%\n",
      "Epoch: 07 | Epoch Time: 2m 1s\n",
      "\tTrain Loss: 0.192 | Train Acc: 92.21%\n",
      "\t Val. Loss: 0.706 |  Val. Acc: 81.93%\n",
      "Epoch: 08 | Epoch Time: 2m 0s\n",
      "\tTrain Loss: 0.180 | Train Acc: 92.87%\n",
      "\t Val. Loss: 0.494 |  Val. Acc: 86.10%\n",
      "Epoch: 09 | Epoch Time: 1m 59s\n",
      "\tTrain Loss: 0.178 | Train Acc: 92.85%\n",
      "\t Val. Loss: 0.496 |  Val. Acc: 85.38%\n",
      "Epoch: 10 | Epoch Time: 2m 0s\n",
      "\tTrain Loss: 0.173 | Train Acc: 92.98%\n",
      "\t Val. Loss: 0.529 |  Val. Acc: 86.88%\n",
      "training time: 1201.8757109642029\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10 # 30\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, dataloader_d['train'], optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, dataloader_d['val'], criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), MODEL_FILE)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "t1 = time.time()\n",
    "train_time = t1 - t0\n",
    "print('training time: {}'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): LSTM(768, 128, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT)\n",
    "model.load_state_dict(torch.load(MODEL_FILE))\n",
    "model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.385 | Test Acc: 86.27%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, dataloader_d['test'], criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
    "\n",
    "results = test_acc, train_time, count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8627256155014038, 1201.8757109642029, 920066)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULTS_FILE, 'wb') as fh:\n",
    "    pickle.dump(results, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Results for 10 epochs witn new dataset!\n",
    "(0.8627256155014038, 1201.8757109642029, 920066)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Results for 10 epochs\n",
    "(0.8747642785310745, 136.26142048835754, 920066)\n",
    "\n",
    "Better than for 30 epochs?!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Results for 30 epochs\n",
    "(0.8602842092514038, 413.11806559562683, 920066)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
