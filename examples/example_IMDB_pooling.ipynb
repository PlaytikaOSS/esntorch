{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a use case example of the ``EsnTorch`` library.\n",
    "It described the implementation of an Echo State Network (ESN)\n",
    "for text classification on the IMDB dataset.\n",
    "\n",
    "The instantiation, training and evaluation of an ESN for text classification\n",
    "is achieved via the following steps:\n",
    "- Import the required modules\n",
    "- Create the dataloaders\n",
    "- Instantiate the ESN by specifying:\n",
    "    - a reservoir\n",
    "    - a loss function\n",
    "    - a learning algorithm\n",
    "- Train the ESN\n",
    "- Training and testing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn\n",
    "# !pip install transformers==4.8.2\n",
    "# !pip install datasets==1.7.0\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tqdm progress bars (on a terminal):\n",
    "1. `conda install -c conda-forge nodejs`\n",
    "2. `jupyter labextension install @jupyter-widgets/jupyterlab-manager`\n",
    "3. `jupyter nbextension enable --py widgetsnbextension`\n",
    "4. `jupyter lab clean`\n",
    "5. Refresh web page..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment this if library is installed\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "import esntorch.core.reservoir as res\n",
    "import esntorch.core.learning_algo as la\n",
    "import esntorch.core.merging_strategy as ms\n",
    "import esntorch.core.esn as esn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device and Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions for loading and preparing data\n",
    "\n",
    "def tokenize(sample):\n",
    "    \"\"\"Tokenize sample\"\"\"\n",
    "    \n",
    "    sample = tokenizer(sample['text'], truncation=True, padding=False, return_length=True)\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def load_and_prepare_dataset(dataset_name, split, cache_dir):\n",
    "    \"\"\"\n",
    "    Load dataset from the datasets library of HuggingFace.\n",
    "    Tokenize and add length.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = load_dataset(dataset_name, split=split, cache_dir=CACHE_DIR)\n",
    "    \n",
    "    # Rename label column for tokenization purposes\n",
    "    dataset = dataset.rename_column('label', 'labels')\n",
    "    \n",
    "    # Tokenize data\n",
    "    dataset = dataset.map(tokenize, batched=True)\n",
    "    dataset = dataset.rename_column('length', 'lengths')\n",
    "    # dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels', 'lengths'])\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (cache_dir/imdb/plain_text/1.0.0/4ea52f2e58a08dbc12c2bd52d0d92b30b88c00230b4522801b3636782f625c5b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b672d25f3a4273a237c26ba169beb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a973f3b77ac4a90a8ba8815ca11f301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4537f60c02af483bac239d5edf15e847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load and prepare data\n",
    "CACHE_DIR = 'cache_dir/' # put your path here\n",
    "\n",
    "full_dataset = load_and_prepare_dataset('imdb', split=None, cache_dir=CACHE_DIR)\n",
    "\n",
    "# *** JUST FOR NOW ***\n",
    "# full_dataset = full_dataset['train'].train_test_split(test_size=0.1)['test'] # sample 10%\n",
    "# full_dataset = full_dataset.train_test_split(test_size=0.2)\n",
    "# for split in full_dataset.keys():\n",
    "#     full_dataset[split] = full_dataset[split].flatten_indices() # needs this to reset indices\n",
    "# *** JUST FOR NOW ***\n",
    "train_dataset = full_dataset['train'].sort(\"lengths\")\n",
    "test_dataset = full_dataset['test'].sort(\"lengths\")\n",
    "\n",
    "# Create dict of all datasets\n",
    "dataset_d = {\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 25000\n",
       " })}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_features(dataset_d):\n",
    "    \"\"\"Compute tf-idf features for the dataset\"\"\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=4000)\n",
    "    vectorizer.fit(dataset_d['train']['text'])\n",
    "    \n",
    "    tfidf_fts = {}\n",
    "    \n",
    "    for split in dataset_d.keys():\n",
    "        X_tmp = vectorizer.transform(dataset_d[split]['text'])\n",
    "        X_tmp = list(X_tmp.todense())\n",
    "        X_tmp = [np.asarray(row).reshape(-1) for row in X_tmp]\n",
    "        tfidf_fts[split] = X_tmp\n",
    "        \n",
    "        dataset_d[split] = dataset_d[split].add_column(\"additional_fts\", X_tmp)\n",
    "        dataset_d[split].set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels', 'lengths', 'additional_fts'])\n",
    "        dataset_d[split] = dataset_d[split].remove_columns(\"text\")\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    return dataset_d, t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_d, fts_time = get_tfidf_features(dataset_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'token_type_ids', 'additional_fts'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'token_type_ids', 'additional_fts'],\n",
       "     num_rows: 25000\n",
       " })}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.66327428817749"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'token_type_ids', 'additional_fts'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'token_type_ids', 'additional_fts'],\n",
       "     num_rows: 25000\n",
       " })}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict of dataloaders\n",
    "\n",
    "dataloader_d = {}\n",
    "\n",
    "for k, v in dataset_d.items():\n",
    "    dataloader_d[k] = torch.utils.data.DataLoader(v, batch_size=256, collate_fn=DataCollatorWithPadding(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f8b60397cd0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f8b60397250>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in dataloader_d['train']:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 4000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['additional_fts'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# ESN parameters\n",
    "esn_params = {\n",
    "            'embedding': 'bert-base-uncased', # TEXT.vocab.vectors,\n",
    "            'distribution' : 'gaussian',              # uniform, gaussian\n",
    "            'input_dim' : 768,                        # dim of BERT encoding!\n",
    "            'reservoir_dim' : 1000,\n",
    "            'input_scaling' : 1.0,\n",
    "            'bias_scaling' : 1.0, # can be None\n",
    "            'sparsity' : 0.99,\n",
    "            'spectral_radius' : 0.9,\n",
    "            'leaking_rate': 0.5,\n",
    "            'activation_function' : 'relu',           # 'tanh', relu'\n",
    "            'mean' : 0.0,\n",
    "            'std' : 1.0,\n",
    "            #'learning_algo' : None, # initialzed below\n",
    "            #'criterion' : None,     # initialzed below\n",
    "            #'optimizer' : None,     # initialzed below\n",
    "            'merging_strategy' : 'mean_and_additional_fts', # 'mean_and_additional_fts', # 'mean'\n",
    "            'bidirectional' : False, # True\n",
    "            'device' : device,\n",
    "            'seed' : 42,\n",
    "            'mode': 'no_layer' # 'esn', 'custom_baseline'\n",
    "             }\n",
    "\n",
    "# Instantiate the ESN\n",
    "ESN = esn.EchoStateNetwork(**esn_params)\n",
    "\n",
    "# Define the learning algo of the ESN\n",
    "ESN.learning_algo = la.RidgeRegression(alpha=10)\n",
    "# ESN.learning_algo = la.RidgeRegression2()\n",
    "# ESN.learning_algo = la.LinearSVC()\n",
    "# ESN.learning_algo = la.LogisticRegression2()\n",
    "\n",
    "# Put the ESN on the device (CPU or GPU)\n",
    "ESN = ESN.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Warm up the ESN on 5 sentences\n",
    "nb_sentences = 5\n",
    "\n",
    "for i in range(nb_sentences): \n",
    "    sentence = dataset_d[\"train\"].select([i])\n",
    "    dataloader_tmp = torch.utils.data.DataLoader(sentence, \n",
    "                                                 batch_size=1, \n",
    "                                                 collate_fn=DataCollatorWithPadding(tokenizer))  \n",
    "\n",
    "    for sentence in dataloader_tmp:\n",
    "        ESN.warm_up(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 31.5 s, total: 2min 19s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training the ESN\n",
    "ESN.fit(dataloader_d[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.532"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train predictions and accuracy\n",
    "train_pred, train_acc = ESN.predict(dataloader_d[\"train\"], verbose=False)\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.272"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test predictions and accuracy\n",
    "test_pred, test_acc = ESN.predict(dataloader_d[\"test\"], verbose=False)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9585    0.9464    0.9524     12500\n",
      "           1     0.9471    0.9590    0.9530     12500\n",
      "\n",
      "    accuracy                         0.9527     25000\n",
      "   macro avg     0.9528    0.9527    0.9527     25000\n",
      "weighted avg     0.9528    0.9527    0.9527     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test classification report\n",
    "print(classification_report(dataset_d['test']['labels'].tolist(),\n",
    "                            test_pred.tolist(),\n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BERT + tf-idf 4000 (no_layer)\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0     0.9585    0.9464    0.9524     12500\n",
    "           1     0.9471    0.9590    0.9530     12500\n",
    "\n",
    "    accuracy                         0.9527     25000\n",
    "   macro avg     0.9528    0.9527    0.9527     25000\n",
    "weighted avg     0.9528    0.9527    0.9527     25000"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# with TF-IDF of 3000 dim, res dim=1000\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0     0.9558    0.9400    0.9478     12500\n",
    "           1     0.9410    0.9566    0.9487     12500\n",
    "\n",
    "    accuracy                         0.9483     25000\n",
    "   macro avg     0.9484    0.9483    0.9483     25000\n",
    "weighted avg     0.9484    0.9483    0.9483     25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dataset_d['train']['text']\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "X_train = vectorizer.fit_transform(corpus)\n",
    "X_test = vectorizer.transform(dataset_d['test']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearSVC()\n",
    "# model = LogisticRegression(C=2)\n",
    "model = RidgeClassifier(alpha=10)\n",
    "\n",
    "model.fit(X_train, dataset_d['train']['labels'])\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9073    0.8845    0.8957     12500\n",
      "           1     0.8873    0.9096    0.8983     12500\n",
      "\n",
      "    accuracy                         0.8970     25000\n",
      "   macro avg     0.8973    0.8970    0.8970     25000\n",
      "weighted avg     0.8973    0.8970    0.8970     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dataset_d['train']['labels'], y_train_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8864    0.8677    0.8769     12500\n",
      "           1     0.8704    0.8888    0.8795     12500\n",
      "\n",
      "    accuracy                         0.8782     25000\n",
      "   macro avg     0.8784    0.8782    0.8782     25000\n",
      "weighted avg     0.8784    0.8782    0.8782     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dataset_d['test']['labels'], y_test_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
