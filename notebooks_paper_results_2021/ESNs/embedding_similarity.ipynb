{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB: TEXT Classification + BERT + Ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "from ax import optimize\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "\n",
    "import esntorch.core.reservoir as res\n",
    "import esntorch.core.learning_algo as la\n",
    "import esntorch.core.merging_strategy as ms\n",
    "import esntorch.core.esn as esn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_fitness(d, return_test_acc=False):\n",
    "    \n",
    "    return fitness(leaking_rate=d['leaking_rate'],\n",
    "                   spectral_radius=d['spectral_radius'],\n",
    "                   input_scaling=d['input_scaling'],\n",
    "                   bias_scaling=d['bias_scaling'],\n",
    "                   alpha=d['alpha'],\n",
    "                   reservoir_dim=d['reservoir_dim'], # will be in the loop\n",
    "                   dataset_d=dataset_d,\n",
    "                   dataloader_d=dataloader_d,\n",
    "                   return_test_acc=return_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"~/Results/Ax_results/ESN/imdb_params_1.pkl\", \"rb\") as fh:\n",
    "    imdb_params = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{500: {'best_parameters': {'leaking_rate': 0.999,\n",
       "   'spectral_radius': 0.5727747785131674,\n",
       "   'input_scaling': 2.2779062575285725,\n",
       "   'bias_scaling': 0.343925600580577,\n",
       "   'alpha': 47.689935194630536,\n",
       "   'reservoir_dim': 500},\n",
       "  'best_values': ({'val_accuracy': 88.40578001236312},\n",
       "   {'val_accuracy': {'val_accuracy': 0.00010199969003581719}}),\n",
       "  'experiment': SimpleExperiment(None)},\n",
       " 1000: {'best_parameters': {'leaking_rate': 0.4987849139827162,\n",
       "   'spectral_radius': 1.6999999999999982,\n",
       "   'input_scaling': 1.4110756942379619,\n",
       "   'bias_scaling': 0.35271864878994974,\n",
       "   'alpha': 103.97613075779954,\n",
       "   'reservoir_dim': 1000},\n",
       "  'best_values': ({'val_accuracy': 89.1698804001885},\n",
       "   {'val_accuracy': {'val_accuracy': 0.0001586215379122042}}),\n",
       "  'experiment': SimpleExperiment(None)},\n",
       " 2000: {'best_parameters': {'leaking_rate': 0.3965251182814235,\n",
       "   'spectral_radius': 1.0298126353747301,\n",
       "   'input_scaling': 0.4442265453597545,\n",
       "   'bias_scaling': 3.0,\n",
       "   'alpha': 107.19441242615346,\n",
       "   'reservoir_dim': 2000},\n",
       "  'best_values': ({'val_accuracy': 89.58264730282428},\n",
       "   {'val_accuracy': {'val_accuracy': 7.956668170559619e-05}}),\n",
       "  'experiment': SimpleExperiment(None)},\n",
       " 3000: {'best_parameters': {'leaking_rate': 0.683064344845724,\n",
       "   'spectral_radius': 1.228961903726664,\n",
       "   'input_scaling': 0.42614603001627893,\n",
       "   'bias_scaling': 0.5405104358050462,\n",
       "   'alpha': 75.01659762893523,\n",
       "   'reservoir_dim': 3000},\n",
       "  'best_values': ({'val_accuracy': 89.72358321870318},\n",
       "   {'val_accuracy': {'val_accuracy': 2.4368995641319435e-05}}),\n",
       "  'experiment': SimpleExperiment(None)},\n",
       " 5000: {'best_parameters': {'leaking_rate': 0.6294520531957551,\n",
       "   'spectral_radius': 1.1160467944441839,\n",
       "   'input_scaling': 2.9999999999946443,\n",
       "   'bias_scaling': 2.748920999418071,\n",
       "   'alpha': 153.95302665906888,\n",
       "   'reservoir_dim': 5000},\n",
       "  'best_values': ({'val_accuracy': 89.99974480382032},\n",
       "   {'val_accuracy': {'val_accuracy': 8.666017627843431e-05}}),\n",
       "  'experiment': SimpleExperiment(None)}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_diff(ESN, return_distances=False):\n",
    "    \n",
    "    input_w = ESN.reservoir.input_w\n",
    "    \n",
    "    with open(\"random_words.csv\", \"rt\") as fh:\n",
    "        random_words = [x[:-1] for x in fh.readlines()]\n",
    "        \n",
    "    tokenized_random_words = tokenizer.batch_encode_plus(random_words, add_special_tokens=False, padding=False)\n",
    "    \n",
    "    simple_words = []\n",
    "    for i,ids in enumerate(tokenized_random_words[\"input_ids\"]):\n",
    "        if len(ids) == 1:\n",
    "            simple_words.append(random_words[i])\n",
    "            \n",
    "    tokenized_simple_random_words = tokenizer.batch_encode_plus(simple_words, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    \n",
    "    # Get BERT embeddings\n",
    "    bert_embedded_words = ESN.reservoir.embedding(tokenized_simple_random_words).squeeze()\n",
    "    \n",
    "    # Get distances $d_{i,j}$\n",
    "    distances_BERT = cosine_distances(bert_embedded_words.cpu().numpy())\n",
    "\n",
    "    # Get transformed BERT embeddings\n",
    "    bert_embedded_words_transformed = torch.mm(bert_embedded_words, input_w.T)\n",
    "\n",
    "    # Get distances $d'_{i,j}$\n",
    "    distances_transformed = cosine_distances(bert_embedded_words_transformed.cpu().numpy())\n",
    "    \n",
    "    # $\\frac{\\sum{|d_{i,j} - d'_{i,j}|}^2}{2*n} $\n",
    "    mse_transformation = ((distances_BERT - distances_transformed) ** 2).mean()/2\n",
    "    \n",
    "    # $\\frac{\\sum{|d_{i,j} - d'_{k,l}|}^2}{2*n}   k,l \\in [1...n]\\text{ randomly}$\n",
    "    random_distances = distances_transformed.flatten()\n",
    "    random_distances = random_distances[random_distances != 0]\n",
    "    random_distances = np.random.choice(random_distances, size=(len(distances_transformed), len(distances_transformed)), replace=True)\n",
    "    np.fill_diagonal(random_distances, 0)\n",
    "    \n",
    "    mse_random = ((distances_BERT - random_distances) ** 2).mean()/2\n",
    "\n",
    "    if return_distances:\n",
    "        return mse_transformation, mse_random, distances_BERT, distances_transformed, random_distances\n",
    "    else:\n",
    "        return mse_transformation, mse_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing size 500\n",
      "\ttesting seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.0006021367153152823\n",
      "\t\tmse of the random transformation : 0.016327379271388054\n",
      "\ttesting seed 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.0008832113235257566\n",
      "\t\tmse of the random transformation : 0.015797536820173264\n",
      "\ttesting seed 16873298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.0006756293587386608\n",
      "\t\tmse of the random transformation : 0.01589079387485981\n",
      "\ttesting seed 1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.0006633711745962501\n",
      "\t\tmse of the random transformation : 0.016319435089826584\n",
      "\ttesting seed 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.0007923736120574176\n",
      "\t\tmse of the random transformation : 0.015535215847194195\n",
      "testing size 1000\n",
      "\ttesting seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.0003902955213561654\n",
      "\t\tmse of the random transformation : 0.015479129739105701\n",
      "\ttesting seed 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.00038061352097429335\n",
      "\t\tmse of the random transformation : 0.015859253704547882\n",
      "\ttesting seed 16873298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.00037621494266204536\n",
      "\t\tmse of the random transformation : 0.015357490628957748\n",
      "\ttesting seed 1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.00034165073884651065\n",
      "\t\tmse of the random transformation : 0.01575501076877117\n",
      "\ttesting seed 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.00031244452111423016\n",
      "\t\tmse of the random transformation : 0.015558995306491852\n",
      "testing size 3000\n",
      "\ttesting seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.00010078657214762643\n",
      "\t\tmse of the random transformation : 0.015603702515363693\n",
      "\ttesting seed 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.00010628730524331331\n",
      "\t\tmse of the random transformation : 0.015626879408955574\n",
      "\ttesting seed 16873298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.00010674318036762998\n",
      "\t\tmse of the random transformation : 0.015474600717425346\n",
      "\ttesting seed 1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.00012406730093061924\n",
      "\t\tmse of the random transformation : 0.015408982522785664\n",
      "\ttesting seed 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.00012528877414297312\n",
      "\t\tmse of the random transformation : 0.015296519733965397\n",
      "testing size 5000\n",
      "\ttesting seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 7.548701978521422e-05\n",
      "\t\tmse of the random transformation : 0.015617839992046356\n",
      "\ttesting seed 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 6.99061420164071e-05\n",
      "\t\tmse of the random transformation : 0.015679847449064255\n",
      "\ttesting seed 16873298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 5.873822374269366e-05\n",
      "\t\tmse of the random transformation : 0.015534666366875172\n",
      "\ttesting seed 1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 7.645990990567952e-05\n",
      "\t\tmse of the random transformation : 0.015333504416048527\n",
      "\ttesting seed 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tmse of the normal transformation : 0.00011495587386889383\n",
      "\t\tmse of the random transformation : 0.015302738174796104\n"
     ]
    }
   ],
   "source": [
    "sum_normal_mse = {}\n",
    "sum_random_mse = {}\n",
    "\n",
    "for size_esn in [500, 1000, 3000, 5000]:\n",
    "    print(f\"testing size {size_esn}\")\n",
    "\n",
    "    best_params = imdb_params[size_esn][\"best_parameters\"]\n",
    "\n",
    "    # parameters\n",
    "    esn_params = {\n",
    "                'embedding_weights': 'bert-base-uncased', # TEXT.vocab.vectors,\n",
    "                'distribution' : 'uniform',              # uniform, gaussian\n",
    "                'input_dim' : 768,                       # dim of encoding!\n",
    "                'reservoir_dim' : best_params[\"reservoir_dim\"],\n",
    "                'bias_scaling' : best_params[\"bias_scaling\"],\n",
    "                'sparsity' : 0.99,\n",
    "                'spectral_radius' : best_params[\"spectral_radius\"],\n",
    "                'leaking_rate': best_params[\"leaking_rate\"],\n",
    "                'activation_function' : 'tanh',\n",
    "                'input_scaling' : best_params[\"input_scaling\"],\n",
    "                'mean' : 0.0,\n",
    "                'std' : 1.0,\n",
    "                'learning_algo' : None,\n",
    "                'criterion' : None,\n",
    "                'optimizer' : None,\n",
    "                'merging_strategy' : 'mean',\n",
    "                'lexicon' : None,\n",
    "                'bidirectional' : False, # False\n",
    "                'device' : device,\n",
    "                'seed' : 42\n",
    "                 }\n",
    "\n",
    "    sum_normal_mse[size_esn] = []\n",
    "    sum_random_mse[size_esn] = []\n",
    "\n",
    "\n",
    "    for seed in [42, 1024, 16873298, 1996, 2019]:\n",
    "        print(f\"\\ttesting seed {seed}\")\n",
    "\n",
    "        esn_params['seed'] = seed\n",
    "\n",
    "        # model\n",
    "        ESN = esn.EchoStateNetwork(**esn_params)\n",
    "        ESN.learning_algo = la.RidgeRegression(alpha = best_params[\"alpha\"])# , mode='normalize')\n",
    "        ESN = ESN.to(device)\n",
    "\n",
    "        mse_transformation, mse_random = compute_mse_diff(ESN)\n",
    "\n",
    "        sum_normal_mse[size_esn].append(mse_transformation)\n",
    "        sum_random_mse[size_esn].append(mse_random)\n",
    "\n",
    "        print(f\"\\t\\tmse of the normal transformation : {mse_transformation}\\n\\t\\tmse of the random transformation : {mse_random}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{500: [0.0006021367153152823,\n",
       "  0.0008832113235257566,\n",
       "  0.0006756293587386608,\n",
       "  0.0006633711745962501,\n",
       "  0.0007923736120574176],\n",
       " 1000: [0.0003902955213561654,\n",
       "  0.00038061352097429335,\n",
       "  0.00037621494266204536,\n",
       "  0.00034165073884651065,\n",
       "  0.00031244452111423016],\n",
       " 3000: [0.00010078657214762643,\n",
       "  0.00010628730524331331,\n",
       "  0.00010674318036762998,\n",
       "  0.00012406730093061924,\n",
       "  0.00012528877414297312],\n",
       " 5000: [7.548701978521422e-05,\n",
       "  6.99061420164071e-05,\n",
       "  5.873822374269366e-05,\n",
       "  7.645990990567952e-05,\n",
       "  0.00011495587386889383]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_normal_mse"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{500: [0.0006021367153152823,\n",
    "  0.0008832113235257566,\n",
    "  0.0006756293587386608,\n",
    "  0.0006633711745962501,\n",
    "  0.0007923736120574176],\n",
    " 1000: [0.0003902955213561654,\n",
    "  0.00038061352097429335,\n",
    "  0.00037621494266204536,\n",
    "  0.00034165073884651065,\n",
    "  0.00031244452111423016],\n",
    " 3000: [0.00010078657214762643,\n",
    "  0.00010628730524331331,\n",
    "  0.00010674318036762998,\n",
    "  0.00012406730093061924,\n",
    "  0.00012528877414297312],\n",
    " 5000: [7.548701978521422e-05,\n",
    "  6.99061420164071e-05,\n",
    "  5.873822374269366e-05,\n",
    "  7.645990990567952e-05,\n",
    "  0.00011495587386889383]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{500: [0.016327379271388054,\n",
       "  0.015797536820173264,\n",
       "  0.01589079387485981,\n",
       "  0.016319435089826584,\n",
       "  0.015535215847194195],\n",
       " 1000: [0.015479129739105701,\n",
       "  0.015859253704547882,\n",
       "  0.015357490628957748,\n",
       "  0.01575501076877117,\n",
       "  0.015558995306491852],\n",
       " 3000: [0.015603702515363693,\n",
       "  0.015626879408955574,\n",
       "  0.015474600717425346,\n",
       "  0.015408982522785664,\n",
       "  0.015296519733965397],\n",
       " 5000: [0.015617839992046356,\n",
       "  0.015679847449064255,\n",
       "  0.015534666366875172,\n",
       "  0.015333504416048527,\n",
       "  0.015302738174796104]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_random_mse"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{500: [0.0006021367153152823,\n",
    "  0.0008832113235257566,\n",
    "  0.0006756293587386608,\n",
    "  0.0006633711745962501,\n",
    "  0.0007923736120574176],\n",
    " 1000: [0.0003902955213561654,\n",
    "  0.00038061352097429335,\n",
    "  0.00037621494266204536,\n",
    "  0.00034165073884651065,\n",
    "  0.00031244452111423016],\n",
    " 3000: [0.00010078657214762643,\n",
    "  0.00010628730524331331,\n",
    "  0.00010674318036762998,\n",
    "  0.00012406730093061924,\n",
    "  0.00012528877414297312],\n",
    " 5000: [7.548701978521422e-05,\n",
    "  6.99061420164071e-05,\n",
    "  5.873822374269366e-05,\n",
    "  7.645990990567952e-05,\n",
    "  0.00011495587386889383]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,3))\n",
    "\n",
    "mse_1 = {k: np.mean(v) for k, v in sum_normal_mse.items()}\n",
    "mse_2 = {k: np.mean(v) for k, v in sum_random_mse.items()}\n",
    "\n",
    "#ax.errorbar(range(len(acc_d)), acc_l, yerr=std_l, fmt='-', color='C1', linewidth=2)\n",
    "ax.plot(range(len(mse_1)), mse_1.values(), marker='o', color='C1', linewidth=3)\n",
    "#ax.plot(range(len(mse_1)), mse_2.values(), marker='o', color='C1', linewidth=3)\n",
    "\n",
    "#ax.set_title('Test Accuracy of an ESN over IMDB dataset')\n",
    "\n",
    "ax.set_xticks(range(len(mse_1)))\n",
    "ax.set_xticklabels(mse_1.keys())\n",
    "\n",
    "ax.set_xlabel('Reservoir dimension')\n",
    "ax.set_ylabel(\"$MSE_{d,d'}$\")\n",
    "\n",
    "plt.savefig(\"MSE_cosine_dist.pdf\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test same thing when passing through reservoir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename correct column as 'labels': depends on the dataset you load\n",
    "\n",
    "def load_and_enrich_dataset(dataset_name, split, cache_dir):\n",
    "    \n",
    "    dataset = load_dataset(dataset_name, split=split, cache_dir=CACHE_DIR)\n",
    "    dataset = dataset.rename_column('label', 'labels') # cf 'imdb' dataset\n",
    "    dataset = dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding=False), batched=True)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "    def add_lengths(sample):\n",
    "        sample[\"lengths\"] = sum(sample[\"input_ids\"] != 0)\n",
    "        return sample\n",
    "    \n",
    "    dataset = dataset.map(add_lengths, batched=False)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/raid/home/jeremiec/huggingface_datasets/imdb/plain_text/1.0.0/4ea52f2e58a08dbc12c2bd52d0d92b30b88c00230b4522801b3636782f625c5b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fabade862b4cdaab3a569a9db41c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed1dbab94384c80a138cd2132d2a611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/raid/home/jeremiec/huggingface_datasets/imdb/plain_text/1.0.0/4ea52f2e58a08dbc12c2bd52d0d92b30b88c00230b4522801b3636782f625c5b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615c8ec732e04ab091f7326f1fc3315e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46820d872e294c7ca2845c935616a0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CACHE_DIR = '~/Data/huggignface/' #put your own path here\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "full_train_dataset = load_and_enrich_dataset('imdb', split='train', cache_dir=CACHE_DIR).sort(\"lengths\") # toriving/sst5\n",
    "train_val_datasets = full_train_dataset.train_test_split(train_size=0.8, shuffle=True)\n",
    "train_dataset = train_val_datasets['train'].sort(\"lengths\")\n",
    "val_dataset = train_val_datasets['test'].sort(\"lengths\")\n",
    "\n",
    "test_dataset = load_and_enrich_dataset('imdb', split='test', cache_dir=CACHE_DIR).sort(\"lengths\")\n",
    "\n",
    "dataset_d = {\n",
    "    'full_train': full_train_dataset,\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset,\n",
    "    'test': test_dataset\n",
    "    }\n",
    "\n",
    "dataloader_d = {}\n",
    "for k, v in dataset_d.items():\n",
    "    dataloader_d[k] = torch.utils.data.DataLoader(v, \n",
    "                                                  batch_size=128,#256, reduced for bi-direction\n",
    "                                                  collate_fn=DataCollatorWithPadding(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_train': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " 'train': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 20000\n",
       " }),\n",
       " 'val': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 5000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 25000\n",
       " })}"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESN.reservoir.initial_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESN.reservoir.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_after_reservoir(ESN, return_distances=False):\n",
    "    \n",
    "    with open(\"random_words.csv\", \"rt\") as fh:\n",
    "        random_words = [x[:-1] for x in fh.readlines()]\n",
    "        \n",
    "    tokenized_random_words = tokenizer.batch_encode_plus(random_words, add_special_tokens=False, padding=False)\n",
    "    \n",
    "    simple_words = []\n",
    "    for i,ids in enumerate(tokenized_random_words[\"input_ids\"]):\n",
    "        if len(ids) == 1:\n",
    "            simple_words.append(random_words[i])\n",
    "            \n",
    "    tokenized_simple_random_words = tokenizer.batch_encode_plus(simple_words, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    \n",
    "    # ESN reservoir parameters\n",
    "    input_w = ESN.reservoir.input_w\n",
    "    reservoir_w = ESN.reservoir.reservoir_w\n",
    "    reservoir_bias = ESN.reservoir.bias\n",
    "    reservoir_x0 = ESN.reservoir.initial_state\n",
    "    \n",
    "    # Get BERT embeddings\n",
    "    bert_embedded_words = ESN.reservoir.embedding(tokenized_simple_random_words).squeeze()\n",
    "    \n",
    "    # Get distances $d_{i,j}$\n",
    "    distances_BERT = cosine_distances(bert_embedded_words.cpu().numpy())\n",
    "\n",
    "    # Get transformed BERT embeddings : apply manually the reservoir once\n",
    "    processing = torch.mm(bert_embedded_words, input_w.T)\n",
    "    inter = torch.mm(reservoir_w, reservoir_x0.reshape((-1, 1))).unsqueeze(0).repeat((785, 1, 1)).squeeze()\n",
    "    processing = processing + inter + reservoir_bias.unsqueeze(0).repeat((785, 1))\n",
    "    bert_embedded_words_transformed = torch.tanh(processing)\n",
    "\n",
    "    # Get distances $d'_{i,j}$\n",
    "    distances_transformed = cosine_distances(bert_embedded_words_transformed.cpu().numpy())\n",
    "    \n",
    "    # $\\frac{\\sum{|d_{i,j} - d'_{i,j}|}^2}{2*n} $\n",
    "    mse_transformation = ((distances_BERT - distances_transformed) ** 2).mean()/2\n",
    "\n",
    "    if return_distances:\n",
    "        return mse_transformation, distances_BERT, distances_transformed\n",
    "    else:\n",
    "        return mse_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_d[\"train\"].select([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing size 500\n",
      "\ttesting seed 42\n",
      "\t\tmse of the normal transformation : 0.006634519435465336\n",
      "\ttesting seed 1024\n",
      "\t\tmse of the normal transformation : 0.0059072538278996944\n",
      "\ttesting seed 16873298\n",
      "\t\tmse of the normal transformation : 0.006588850170373917\n",
      "\ttesting seed 1996\n",
      "\t\tmse of the normal transformation : 0.006834477186203003\n",
      "\ttesting seed 2019\n",
      "\t\tmse of the normal transformation : 0.007324102334678173\n",
      "testing size 1000\n",
      "\ttesting seed 42\n",
      "\t\tmse of the normal transformation : 0.0046043312177062035\n",
      "\ttesting seed 1024\n",
      "\t\tmse of the normal transformation : 0.0050125219859182835\n",
      "\ttesting seed 16873298\n",
      "\t\tmse of the normal transformation : 0.005555033218115568\n",
      "\ttesting seed 1996\n",
      "\t\tmse of the normal transformation : 0.0062471111305058\n",
      "\ttesting seed 2019\n",
      "\t\tmse of the normal transformation : 0.005521882325410843\n",
      "testing size 3000\n",
      "\ttesting seed 42\n",
      "\t\tmse of the normal transformation : 0.001587049919180572\n",
      "\ttesting seed 1024\n",
      "\t\tmse of the normal transformation : 0.0015077058924362063\n",
      "\ttesting seed 16873298\n",
      "\t\tmse of the normal transformation : 0.0011666826903820038\n",
      "\ttesting seed 1996\n",
      "\t\tmse of the normal transformation : 0.0013198679080232978\n",
      "\ttesting seed 2019\n",
      "\t\tmse of the normal transformation : 0.0012530178064480424\n",
      "testing size 5000\n",
      "\ttesting seed 42\n",
      "\t\tmse of the normal transformation : 0.007224132306873798\n",
      "\ttesting seed 1024\n",
      "\t\tmse of the normal transformation : 0.006628277245908976\n",
      "\ttesting seed 16873298\n",
      "\t\tmse of the normal transformation : 0.0064443303272128105\n",
      "\ttesting seed 1996\n",
      "\t\tmse of the normal transformation : 0.006674686912447214\n",
      "\ttesting seed 2019\n",
      "\t\tmse of the normal transformation : 0.005829368717968464\n"
     ]
    }
   ],
   "source": [
    "sum_normal_mse = {}\n",
    "\n",
    "for size_esn in [500, 1000, 3000, 5000]:\n",
    "    print(f\"testing size {size_esn}\")\n",
    "\n",
    "    best_params = imdb_params[size_esn][\"best_parameters\"]\n",
    "\n",
    "    # parameters\n",
    "    esn_params = {\n",
    "                'embedding_weights': 'bert-base-uncased', # TEXT.vocab.vectors,\n",
    "                'distribution' : 'uniform',              # uniform, gaussian\n",
    "                'input_dim' : 768,                       # dim of encoding!\n",
    "                'reservoir_dim' : best_params[\"reservoir_dim\"],\n",
    "                'bias_scaling' : best_params[\"bias_scaling\"],\n",
    "                'sparsity' : 0.99,\n",
    "                'spectral_radius' : best_params[\"spectral_radius\"],\n",
    "                'leaking_rate': best_params[\"leaking_rate\"],\n",
    "                'activation_function' : 'tanh',\n",
    "                'input_scaling' : best_params[\"input_scaling\"],\n",
    "                'mean' : 0.0,\n",
    "                'std' : 1.0,\n",
    "                'learning_algo' : None,\n",
    "                'criterion' : None,\n",
    "                'optimizer' : None,\n",
    "                'merging_strategy' : 'mean',\n",
    "                'lexicon' : None,\n",
    "                'bidirectional' : False, # False\n",
    "                'device' : device,\n",
    "                'seed' : 42\n",
    "                 }\n",
    "\n",
    "    sum_normal_mse[size_esn] = []\n",
    "\n",
    "\n",
    "    for seed in [42, 1024, 16873298, 1996, 2019]:\n",
    "        print(f\"\\ttesting seed {seed}\")\n",
    "\n",
    "        esn_params['seed'] = seed\n",
    "\n",
    "        # model\n",
    "        ESN = esn.EchoStateNetwork(**esn_params)\n",
    "        ESN.learning_algo = la.RidgeRegression(alpha = best_params[\"alpha\"])# , mode='normalize')\n",
    "        ESN = ESN.to(device)\n",
    "        \n",
    "        # warm up (new)\n",
    "        nb_sentences = 3\n",
    "        for i in range(nb_sentences): \n",
    "\n",
    "            sentence = dataset_d[\"train\"].select([i])\n",
    "            dataloader_tmp = torch.utils.data.DataLoader(sentence, \n",
    "                                                         batch_size=1, \n",
    "                                                         collate_fn=DataCollatorWithPadding(tokenizer))  \n",
    "\n",
    "            for s in dataloader_tmp:\n",
    "                ESN.warm_up(s)\n",
    "\n",
    "        mse_transformation = compute_mse_after_reservoir(ESN)\n",
    "\n",
    "        sum_normal_mse[size_esn].append(mse_transformation)\n",
    "\n",
    "        print(f\"\\t\\tmse of the normal transformation : {mse_transformation}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "testing size 500\n",
    "\ttesting seed 42\n",
    "\t\tmse of the normal transformation : 0.006634519435465336\n",
    "\ttesting seed 1024\n",
    "\t\tmse of the normal transformation : 0.0059072538278996944\n",
    "\ttesting seed 16873298\n",
    "\t\tmse of the normal transformation : 0.006588850170373917\n",
    "\ttesting seed 1996\n",
    "\t\tmse of the normal transformation : 0.006834477186203003\n",
    "\ttesting seed 2019\n",
    "\t\tmse of the normal transformation : 0.007324102334678173\n",
    "testing size 1000\n",
    "\ttesting seed 42\n",
    "\t\tmse of the normal transformation : 0.0046043312177062035\n",
    "\ttesting seed 1024\n",
    "\t\tmse of the normal transformation : 0.0050125219859182835\n",
    "\ttesting seed 16873298\n",
    "\t\tmse of the normal transformation : 0.005555033218115568\n",
    "\ttesting seed 1996\n",
    "\t\tmse of the normal transformation : 0.0062471111305058\n",
    "\ttesting seed 2019\n",
    "\t\tmse of the normal transformation : 0.005521882325410843\n",
    "testing size 3000\n",
    "\ttesting seed 42\n",
    "\t\tmse of the normal transformation : 0.001587049919180572\n",
    "\ttesting seed 1024\n",
    "\t\tmse of the normal transformation : 0.0015077058924362063\n",
    "\ttesting seed 16873298\n",
    "\t\tmse of the normal transformation : 0.0011666826903820038\n",
    "\ttesting seed 1996\n",
    "\t\tmse of the normal transformation : 0.0013198679080232978\n",
    "\ttesting seed 2019\n",
    "\t\tmse of the normal transformation : 0.0012530178064480424\n",
    "testing size 5000\n",
    "\ttesting seed 42\n",
    "\t\tmse of the normal transformation : 0.007224132306873798\n",
    "\ttesting seed 1024\n",
    "\t\tmse of the normal transformation : 0.006628277245908976\n",
    "\ttesting seed 16873298\n",
    "\t\tmse of the normal transformation : 0.0064443303272128105\n",
    "\ttesting seed 1996\n",
    "\t\tmse of the normal transformation : 0.006674686912447214\n",
    "\ttesting seed 2019\n",
    "\t\tmse of the normal transformation : 0.005829368717968464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
