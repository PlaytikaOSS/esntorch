{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AG NEWS\n",
    "# DistilBERT finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification, AdamW\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 24 # cf. paper Sun et al.\n",
    "NB_EPOCHS = 4   # cf. paper Sun et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENT_PATH = '~/Results/BERT_finetune' # put your path here\n",
    "CURRENT_PATH = '/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILE = os.path.join(CURRENT_PATH, 'ag_news_results.pkl')\n",
    "RESULTS_DIR = os.path.join(CURRENT_PATH,'ag_news/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CACHE_DIR = '~/Data/huggignface/'         # put your path here\n",
    "CACHE_DIR = '/raid/home/jeremiec/huggingface_datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/raid/home/jeremiec/huggingface_datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e291cc70d3e4b01b0c817ef4664e465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download dataset\n",
    "\n",
    "raw_datasets = load_dataset('ag_news', cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5cc1d1afb746a3ba2f4b9f37b04aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f787df049aa4943986efae405ea5671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "train_val_datasets = train_dataset.train_test_split(train_size=0.8)\n",
    "\n",
    "train_dataset = train_val_datasets['train'].rename_column('label', 'labels')\n",
    "val_dataset = train_val_datasets['test'].rename_column('label', 'labels')\n",
    "test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).rename_column('label', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of labels\n",
    "\n",
    "num_labels = len(set(train_dataset['labels'].tolist()))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # output\n",
    "    output_dir=RESULTS_DIR,          \n",
    "    \n",
    "    # params\n",
    "    num_train_epochs=NB_EPOCHS,               # nb of epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,    # cf. paper Sun et al.\n",
    "    learning_rate=2e-5,                       # cf. paper Sun et al.\n",
    "#     warmup_steps=500,                         # number of warmup steps for learning rate scheduler\n",
    "    warmup_ratio=0.1,                         # cf. paper Sun et al.\n",
    "    weight_decay=0.01,                        # strength of weight decay\n",
    "    \n",
    "#     # eval\n",
    "    evaluation_strategy=\"steps\",              # cf. paper Sun et al.\n",
    "    eval_steps=50, # 20                       # cf. paper Sun et al.\n",
    "#     evaluation_strategy='no', # no more evaluation, takes time\n",
    "    \n",
    "    # log\n",
    "    logging_dir=RESULTS_DIR+'logs',  \n",
    "    logging_strategy='steps',\n",
    "    logging_steps=50, # 20\n",
    "    \n",
    "    # save\n",
    "    save_strategy='steps',\n",
    "    save_total_limit=1,\n",
    "    # save_steps=20, # default 500\n",
    "    load_best_model_at_end=True,              # cf. paper Sun et al.\n",
    "    metric_for_best_model='eval_loss'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    \n",
    "    return {\"val_accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    # compute_metrics=compute_metrics,\n",
    "    # callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 96000\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 24\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16000' max='16000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16000/16000 8:47:38, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.394500</td>\n",
       "      <td>1.389820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.380900</td>\n",
       "      <td>1.367151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.346100</td>\n",
       "      <td>1.308515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.243600</td>\n",
       "      <td>1.130099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.851229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>0.603101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.548700</td>\n",
       "      <td>0.462756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.402666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>0.363642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.338506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.334100</td>\n",
       "      <td>0.321320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.310013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.326862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.289525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.340100</td>\n",
       "      <td>0.278103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.332200</td>\n",
       "      <td>0.271780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.304600</td>\n",
       "      <td>0.270508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>0.270087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.286600</td>\n",
       "      <td>0.287519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.255564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.242070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.266900</td>\n",
       "      <td>0.259345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.279900</td>\n",
       "      <td>0.261364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.237200</td>\n",
       "      <td>0.243764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.219100</td>\n",
       "      <td>0.247443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.279500</td>\n",
       "      <td>0.235234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.236900</td>\n",
       "      <td>0.218545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>0.227226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.260200</td>\n",
       "      <td>0.224080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.223308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.290200</td>\n",
       "      <td>0.229546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.242300</td>\n",
       "      <td>0.219951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.283300</td>\n",
       "      <td>0.224558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.248100</td>\n",
       "      <td>0.216753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.262400</td>\n",
       "      <td>0.242703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.255757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.230100</td>\n",
       "      <td>0.221848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.207828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>0.203555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.244300</td>\n",
       "      <td>0.204647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.208933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.219155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.198100</td>\n",
       "      <td>0.203317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>0.196891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.219509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.251900</td>\n",
       "      <td>0.214875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.200994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.197455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.240700</td>\n",
       "      <td>0.199880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.212244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.235500</td>\n",
       "      <td>0.205092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>0.196518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.223800</td>\n",
       "      <td>0.193419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.212400</td>\n",
       "      <td>0.201343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.220813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.198811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.196491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.198200</td>\n",
       "      <td>0.191857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.187314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.174100</td>\n",
       "      <td>0.188237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.207900</td>\n",
       "      <td>0.204231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.228500</td>\n",
       "      <td>0.200608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.190711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.244300</td>\n",
       "      <td>0.216064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.196900</td>\n",
       "      <td>0.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.186209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.217700</td>\n",
       "      <td>0.191584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.185511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.187602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.183744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.182083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.194599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.199500</td>\n",
       "      <td>0.181798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.175500</td>\n",
       "      <td>0.179625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.189348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.216100</td>\n",
       "      <td>0.176548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.171100</td>\n",
       "      <td>0.188885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.181795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.184803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.201356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.201800</td>\n",
       "      <td>0.179165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.191414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.179623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.181451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.178908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.194435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.184495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.133600</td>\n",
       "      <td>0.186176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.180151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>0.179693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.185426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.192541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.178844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.185842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.181329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.171700</td>\n",
       "      <td>0.182396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.197290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.191750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.197471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.191091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>0.176983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.177364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>0.162400</td>\n",
       "      <td>0.194208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.175625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.175497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.175742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.170630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.173479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.176582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.188053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.187534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.219600</td>\n",
       "      <td>0.178952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.177969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.186612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>0.161600</td>\n",
       "      <td>0.207293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.179155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.178006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.180207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5950</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.189126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.189181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6050</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.187551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.183750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6150</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.181347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.185843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.174435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.176299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6350</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.175212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.179969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6450</td>\n",
       "      <td>0.158600</td>\n",
       "      <td>0.170731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>0.174928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6550</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.173320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>0.178753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6650</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.173550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.176070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.180745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.177169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6850</td>\n",
       "      <td>0.128300</td>\n",
       "      <td>0.187273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.161200</td>\n",
       "      <td>0.170438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6950</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.181161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.171273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7050</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.177374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>0.182471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7150</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.186620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.181100</td>\n",
       "      <td>0.171119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>0.141300</td>\n",
       "      <td>0.173466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.154700</td>\n",
       "      <td>0.178922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7350</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.172581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.127400</td>\n",
       "      <td>0.164731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7450</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.173614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.164890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7550</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.170921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.177605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7650</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.175768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>0.192023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>0.162400</td>\n",
       "      <td>0.179975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.166835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7850</td>\n",
       "      <td>0.141300</td>\n",
       "      <td>0.176037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.169814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7950</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.167795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.158600</td>\n",
       "      <td>0.167929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8050</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.177244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.175896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8150</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.188573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.189152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8250</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.189905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>0.199510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8350</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>0.197605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.209661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8450</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.195857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.204582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8550</td>\n",
       "      <td>0.108500</td>\n",
       "      <td>0.195936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>0.195033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8650</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>0.194257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.204038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8750</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.181073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.182702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8850</td>\n",
       "      <td>0.107800</td>\n",
       "      <td>0.192844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.192742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8950</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.196134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.181322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9050</td>\n",
       "      <td>0.116800</td>\n",
       "      <td>0.193759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.192011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9150</td>\n",
       "      <td>0.108200</td>\n",
       "      <td>0.191231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.189955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9250</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>0.192577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.197019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9350</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.201793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.194399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9450</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>0.191701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>0.190160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9550</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.188558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.101300</td>\n",
       "      <td>0.186682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9650</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.186055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.192571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9750</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.189812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.184081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9850</td>\n",
       "      <td>0.101300</td>\n",
       "      <td>0.184114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.191901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9950</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.186699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.184593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10050</td>\n",
       "      <td>0.151800</td>\n",
       "      <td>0.180527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.185780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10150</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.192143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.188396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10250</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.184407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.186185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10350</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.195659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.188092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10450</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.187426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>0.189473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10550</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.189834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.193533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10650</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.188868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.185355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10750</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.186272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>0.188303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10850</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.191800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.191674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10950</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.193830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.194619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11050</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.188848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.192108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11150</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.192240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.190787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11250</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.193553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.118200</td>\n",
       "      <td>0.192429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11350</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.185882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.186626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11450</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.189836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.184943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11550</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.183084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.183266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11650</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.184590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>0.192365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11750</td>\n",
       "      <td>0.112400</td>\n",
       "      <td>0.188494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.189843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11850</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>0.182619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.180145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11950</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.180505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.180067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12050</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.187179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.194091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12150</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.191655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.196581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12250</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>0.197532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.202540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12350</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>0.202148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.202706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12450</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.204764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.200804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12550</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.204385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.201785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12650</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.201921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.210431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12750</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.210773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.210690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12850</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.210647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.210974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12950</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.214428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.051800</td>\n",
       "      <td>0.215324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13050</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.220054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.218368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13150</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.218185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.219840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13250</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.219743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.225529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13350</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.213551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>0.220544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13450</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.217619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.218629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13550</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.218240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.215124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13650</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.210844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>0.213690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13750</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.215629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.217589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13850</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.217784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13900</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.221833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13950</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.216256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.216877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14050</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.218394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14100</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.216314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14150</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>0.215573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.213137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14250</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.218192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14300</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.214633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14350</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.211655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.211692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14450</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.215161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.215300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14550</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.216140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.214553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14650</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.212233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14700</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.214554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14750</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.214113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.214733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14850</td>\n",
       "      <td>0.054300</td>\n",
       "      <td>0.216485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14900</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.217862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14950</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.218325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.217066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15050</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.219961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15100</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.218306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15150</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.218684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.094100</td>\n",
       "      <td>0.218072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15250</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.218945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15300</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.218572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15350</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.217863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.217920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15450</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.217962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.218214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15550</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.217778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.216740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15650</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.217029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15700</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.217411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15750</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.217723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.217854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15850</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.217732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15900</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.217887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15950</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.217944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.217998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-1500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-2500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-3500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-5500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-4500] due to args.save_total_limit\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-6500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-8500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-9500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-10500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-11500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-12500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-13500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-14500] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15500\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24000\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-16000\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-16000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-15500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint-7500 (score: 0.1648896336555481).\n"
     ]
    }
   ],
   "source": [
    "results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7914.910725"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_time = results.metrics[\"train_runtime\"]\n",
    "training_time_per_epoch = training_time / training_args.num_train_epochs\n",
    "training_time_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint_best_model\n",
      "Configuration saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint_best_model/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint_best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint_best_model/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint_best_model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(os.path.join(RESULTS_DIR, 'checkpoint_best_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint_best_model/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint_best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at /raid/home/jeremiec/Ax_results/DistilBERT_finetune_v2/ag_news/checkpoint_best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='950' max='950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [950/950 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "model_file = os.path.join(RESULTS_DIR, 'checkpoint_best_model')\n",
    "finetuned_model = DistilBertForSequenceClassification.from_pretrained(model_file, num_labels=num_labels)\n",
    "finetuned_model.to(device)\n",
    "finetuned_model.eval()\n",
    "\n",
    "# compute test acc\n",
    "test_trainer = Trainer(finetuned_model, data_collator=DataCollatorWithPadding(tokenizer))\n",
    "raw_preds, labels, _ = test_trainer.predict(test_dataset)\n",
    "preds = np.argmax(raw_preds, axis=1)\n",
    "test_acc = accuracy_score(y_true=labels, y_pred=preds)\n",
    "\n",
    "# save results\n",
    "results_d = {}\n",
    "results_d['accuracy'] = test_acc\n",
    "results_d['training_time'] = training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9417105263157894, 'training_time': 31659.6429}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "\n",
    "with open(RESULTS_FILE, 'wb') as fh:\n",
    "    pickle.dump(results_d, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
