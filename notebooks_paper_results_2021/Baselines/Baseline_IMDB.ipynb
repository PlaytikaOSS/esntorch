{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline IMDB: TEXT Classification + BERT + Ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need ``datasets==1.7.0``\n",
    "- Need ``ax-platform==0.1.20``\n",
    "\n",
    "Install them from command line if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "from ax import optimize\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax.service.managed_loop import optimize\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "\n",
    "import esntorch.core.reservoir as res\n",
    "import esntorch.core.learning_algo as la\n",
    "import esntorch.core.merging_strategy as ms\n",
    "import esntorch.core.baseline as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = '~/Results/Ax_results/Baseline' # path of your result folder\n",
    "CACHE_DIR = '~/Data/huggignface/'              # path of your  folder\n",
    "\n",
    "PARAMS_FILE = 'imdb_baseline_params.pkl'\n",
    "RESULTS_FILE = 'imdb_baseline_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename correct column as 'labels': depends on the dataset you load\n",
    "\n",
    "def load_and_enrich_dataset(dataset_name, split, cache_dir):\n",
    "    \n",
    "    dataset = load_dataset(dataset_name, split=split, cache_dir=CACHE_DIR)\n",
    "    \n",
    "    dataset = dataset.rename_column('label', 'labels') # cf 'imdb' dataset\n",
    "    dataset = dataset.map(lambda e: tokenizer(e['text'], truncation=True, padding=False), batched=True)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "    def add_lengths(sample):\n",
    "        sample[\"lengths\"] = sum(sample[\"input_ids\"] != 0)\n",
    "        return sample\n",
    "    \n",
    "    dataset = dataset.map(add_lengths, batched=False)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/raid/home/jeremiec/huggingface_datasets/imdb/plain_text/1.0.0/4ea52f2e58a08dbc12c2bd52d0d92b30b88c00230b4522801b3636782f625c5b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2685985eb1654149a70a79ff9144f812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa97ff7903649be99b4fbaebeae7010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/raid/home/jeremiec/huggingface_datasets/imdb/plain_text/1.0.0/4ea52f2e58a08dbc12c2bd52d0d92b30b88c00230b4522801b3636782f625c5b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f67b89fa1a4f70bbffb499cc0ba604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912672636cec4653aed26cb6e823e2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "full_train_dataset = load_and_enrich_dataset('imdb', split='train', cache_dir=CACHE_DIR).sort(\"lengths\") # toriving/sst5\n",
    "train_val_datasets = full_train_dataset.train_test_split(train_size=0.8, shuffle=True)\n",
    "train_dataset = train_val_datasets['train'].sort(\"lengths\")\n",
    "val_dataset = train_val_datasets['test'].sort(\"lengths\")\n",
    "\n",
    "test_dataset = load_and_enrich_dataset('imdb', split='test', cache_dir=CACHE_DIR).sort(\"lengths\")\n",
    "\n",
    "dataset_d = {\n",
    "    'full_train': full_train_dataset,\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset,\n",
    "    'test': test_dataset\n",
    "    }\n",
    "\n",
    "dataloader_d = {}\n",
    "for k, v in dataset_d.items():\n",
    "    dataloader_d[k] = torch.utils.data.DataLoader(v, batch_size=256, collate_fn=DataCollatorWithPadding(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_train': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " 'train': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 20000\n",
       " }),\n",
       " 'val': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 5000\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['attention_mask', 'input_ids', 'labels', 'lengths', 'text', 'token_type_ids'],\n",
       "     num_rows: 25000\n",
       " })}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(alpha, \n",
    "            dataset_d, \n",
    "            dataloader_d, \n",
    "            return_test_acc=False):\n",
    "    \n",
    "    # parameters\n",
    "    esn_params = {\n",
    "                'embedding_weights': 'bert-base-uncased', # TEXT.vocab.vectors,\n",
    "                'input_dim' : 768,                        # dim of encoding!\n",
    "                'learning_algo' : None,\n",
    "                'criterion' : None,\n",
    "                'optimizer' : None,\n",
    "                'merging_strategy' : 'mean',\n",
    "                'lexicon' : None,\n",
    "                'bidirectional' : False,\n",
    "                'device' : device,\n",
    "                'seed' : 42\n",
    "                 }\n",
    "\n",
    "    # model\n",
    "    ESN = bs.Baseline(**esn_params)\n",
    "\n",
    "    ESN.learning_algo = la.RidgeRegression(alpha = alpha)# , mode='normalize')\n",
    "\n",
    "    ESN = ESN.to(device)\n",
    "\n",
    "    # predict\n",
    "    if return_test_acc:\n",
    "        t0 = timer()\n",
    "        LOSS = ESN.fit(dataloader_d[\"train\"])\n",
    "        t1 = timer()\n",
    "        acc = ESN.predict(dataloader_d[\"test\"], verbose=False)[1].item()\n",
    "    else:\n",
    "        LOSS = ESN.fit(dataloader_d[\"train\"])\n",
    "        acc = ESN.predict(dataloader_d[\"val\"], verbose=False)[1].item()\n",
    "\n",
    "    # clean objects\n",
    "    del ESN.learning_algo\n",
    "    del ESN.criterion\n",
    "    del ESN.merging_strategy\n",
    "    del ESN\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    if return_test_acc:\n",
    "        return acc, t1 - t0 \n",
    "    else:\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%time\n",
    "\n",
    "# fitness(alpha=10, dataset_d=dataset_d, dataloader_d=dataloader_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_fitness(d, return_test_acc=False):\n",
    "    \n",
    "    return fitness(alpha=d['alpha'],\n",
    "                   dataset_d=dataset_d,\n",
    "                   dataloader_d=dataloader_d,\n",
    "                   return_test_acc=return_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-30 11:56:06] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n",
      "[INFO 05-30 11:56:06] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 05-30 11:56:06] ax.service.managed_loop: Running optimization trial 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-30 11:58:15] ax.service.managed_loop: Running optimization trial 2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-30 12:00:20] ax.service.managed_loop: Running optimization trial 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-30 12:02:25] ax.service.managed_loop: Running optimization trial 4...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-30 12:04:30] ax.service.managed_loop: Running optimization trial 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-30 12:06:35] ax.service.managed_loop: Running optimization trial 6...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-30 12:09:01] ax.service.managed_loop: Running optimization trial 7...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR 05-30 12:11:51] ax.service.managed_loop: CUDA out of memory. Tried to allocate 3.00 GiB (GPU 0; 31.75 GiB total capacity; 9.12 GiB already allocated; 1.66 GiB free; 14.78 GiB reserved in total by PyTorch)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dgx/.local/lib/python3.8/site-packages/ax/utils/common/executils.py\", line 98, in actual_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dgx/.local/lib/python3.8/site-packages/ax/service/managed_loop.py\", line 168, in run_trial\n",
      "    trial.fetch_data()\n",
      "  File \"/home/dgx/.local/lib/python3.8/site-packages/ax/core/base_trial.py\", line 372, in fetch_data\n",
      "    return self.experiment._fetch_trial_data(\n",
      "  File \"/home/dgx/.local/lib/python3.8/site-packages/ax/core/simple_experiment.py\", line 223, in _fetch_trial_data\n",
      "    return self.eval_trial(self.trials[trial_index])\n",
      "  File \"/home/dgx/.local/lib/python3.8/site-packages/ax/core/simple_experiment.py\", line 126, in eval_trial\n",
      "    evaluations[not_none(trial.arm).name] = self.evaluation_function_outer(\n",
      "  File \"/home/dgx/.local/lib/python3.8/site-packages/ax/core/simple_experiment.py\", line 186, in evaluation_function_outer\n",
      "    evaluation = self._evaluation_function(parameterization, weight)\n",
      "  File \"<ipython-input-13-27afd25500b6>\", line 3, in wrapped_fitness\n",
      "    return fitness(alpha=d['alpha'],\n",
      "  File \"<ipython-input-11-268bcf7dd881>\", line 34, in fitness\n",
      "    LOSS = ESN.fit(dataloader_d[\"train\"])\n",
      "  File \"/home/dgx/dev/esn_torch/src/models/esn.py\", line 341, in fit\n",
      "    return self._fit_direct(train_dataloader)\n",
      "  File \"/home/dgx/dev/esn_torch/src/models/esn.py\", line 212, in _fit_direct\n",
      "    states, lengths = self.reservoir.forward(batch_text)   # states\n",
      "  File \"/home/dgx/dev/esn_torch/src/models/reservoir.py\", line 425, in forward\n",
      "    embedded_inputs = self.embedding(batch).transpose(0, 1)\n",
      "  File \"/home/dgx/dev/esn_torch/src/models/reservoir.py\", line 65, in <lambda>\n",
      "    self.embedding = lambda batch: self.HuggingFaceEmbedding.get_embedding(batch)\n",
      "  File \"/home/dgx/dev/esn_torch/src/utils/embedding.py\", line 61, in get_embedding\n",
      "    batch_emb = self.model(batch[\"input_ids\"], batch[\"attention_mask\"])[0].transpose(0, 1)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 971, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 568, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 456, in forward\n",
      "    self_attention_outputs = self.attention(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 387, in forward\n",
      "    self_outputs = self.self(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 309, in forward\n",
      "    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 3.00 GiB (GPU 0; 31.75 GiB total capacity; 9.12 GiB already allocated; 1.66 GiB free; 14.78 GiB reserved in total by PyTorch)\n",
      "[INFO 05-30 12:11:51] ax.service.managed_loop: Running optimization trial 7...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n",
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-30 12:16:20] ax.service.managed_loop: Running optimization trial 8...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-30 12:18:25] ax.service.managed_loop: Running optimization trial 9...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-30 12:20:31] ax.service.managed_loop: Running optimization trial 10...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n"
     ]
    }
   ],
   "source": [
    "best_params_d = {}\n",
    "\n",
    "best_parameters, best_values, experiment, model = optimize(\n",
    "        parameters=[\n",
    "          {\n",
    "            \"name\": \"alpha\",\n",
    "            \"value_type\": \"float\",\n",
    "            \"type\": \"range\",\n",
    "            \"log_scale\": True,\n",
    "            \"bounds\": [1e-3, 1e3],\n",
    "          }\n",
    "        ],\n",
    "        # Booth function\n",
    "        evaluation_function = wrapped_fitness,\n",
    "        minimize = False,\n",
    "        objective_name = 'val_accuracy',\n",
    "        total_trials = 10\n",
    "    )\n",
    "\n",
    "# results\n",
    "best_params_d['best_parameters'] = best_parameters\n",
    "best_params_d['best_values'] = best_values\n",
    "best_params_d['experiment'] = experiment\n",
    "# best_params_d[res_dim]['model'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters\n",
    "\n",
    "with open(os.path.join(RESULTS_PATH, PARAMS_FILE), 'wb') as fh:\n",
    "    pickle.dump(best_params_d, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load results\n",
    "# with open(os.path.join(RESULTS_PATH, PARAMS_FILE), 'rb') as fh:\n",
    "#     best_params_d = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_parameters': {'alpha': 29.805835926637286},\n",
       " 'best_values': ({'val_accuracy': 89.46525653340942},\n",
       "  {'val_accuracy': {'val_accuracy': 0.006979802321755369}}),\n",
       " 'experiment': SimpleExperiment(None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid distribution of reservoir ('uniform' or 'gaussian')...\n",
      "Activation function unknown...\n",
      "Experiment finished.\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "\n",
    "best_parameters = best_params_d['best_parameters']\n",
    "acc, time = wrapped_fitness(best_parameters, return_test_acc=True)\n",
    "results_tuple = acc, time\n",
    "print(\"Experiment finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88.45600128173828, 97.09239137393888)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_PATH, RESULTS_FILE), 'wb') as fh:\n",
    "    pickle.dump(results_tuple, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
